{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ffddce",
   "metadata": {},
   "source": [
    "# tong hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cc9298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 1/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/tin-moi-nhat.rss\n",
      "Found 54 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 54 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 2/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/thoi-su.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 3/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/the-gioi.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 4/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/kinh-doanh.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 5/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/giai-tri.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 6/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/the-thao.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 7/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/phap-luat.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 8/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/giao-duc.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 9/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/suc-khoe.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 10/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/gia-dinh.rss\n",
      "Found 60 entries in RSS feed\n",
      "Added: Mặc áo dài màu gì để trẻ và tôn da dịp Tết?\n",
      "\n",
      "Summary: 1 added, 59 duplicates, 0 old\n",
      "✓ Added 1 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 11/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/du-lich.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 12/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/khoa-hoc.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 13/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/so-hoa.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 14/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/oto-xe-may.rss\n",
      "Found 60 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 60 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 15/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vnexpress.net/rss/y-kien.rss\n",
      "Found 60 entries in RSS feed\n",
      "Added: FOMO vàng, bạc, đồng\n",
      "\n",
      "Summary: 1 added, 59 duplicates, 0 old\n",
      "✓ Added 1 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 16/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://dantri.com.vn/rss/trang-chu.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 17/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://dantri.com.vn/rss/xa-hoi.rss\n",
      "Found 100 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 0 duplicates, 100 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 18/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://dantri.com.vn/rss/the-gioi.rss\n",
      "Found 100 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 100 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 19/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://dantri.com.vn/rss/kinh-doanh.rss\n",
      "Found 100 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 100 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 20/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://dantri.com.vn/rss/the-thao.rss\n",
      "Found 100 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 100 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 21/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://dantri.com.vn/rss/giai-tri.rss\n",
      "Found 100 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 100 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 22/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://dantri.com.vn/rss/giao-duc.rss\n",
      "Found 100 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 100 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 23/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://dantri.com.vn/rss/suc-khoe.rss\n",
      "Found 100 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 100 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 24/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://dantri.com.vn/rss/du-lich.rss\n",
      "Found 100 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 100 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 25/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://dantri.com.vn/rss/o-to-xe-may.rss\n",
      "Found 100 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 100 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 26/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://tuoitre.vn/rss/tin-moi-nhat.rss\n",
      "Found 50 entries in RSS feed\n",
      "Added: Lãnh đạo Đồng Nai mang 'Xuân biên giới' đến tuyến đầu Tà Thiết\n",
      "Added: Liên kết vùng 'mở khóa' dòng vốn cho trung tâm kinh tế phía Nam\n",
      "Added: Tai nạn liên tiếp trên cao tốc, Cục CSGT cảnh báo 2 lỗi 'chết người'\n",
      "Added: Tổng Bí thư Tô Lâm gặp mặt cán bộ công an cấp cao qua các thời kỳ\n",
      "Added: Cử tri nơi cư trú giới thiệu Bí thư Cần Thơ Lê Quang Tùng ứng cử đại biểu Quốc h\n",
      "Added: Nga tuyên bố ‘không thể chấp nhận’ việc NATO đưa quân vào Ukraine sau ngừng bắn\n",
      "Added: Rà soát thiết bị giám sát tàu cá tại TP.HCM, đẩy mạnh chống khai thác IUU\n",
      "Added: Nhật Bản: Tuyết rơi dữ dội, cụ bà bị vùi dưới tuyết dày 3m\n",
      "Added: Xã Bình Lợi, TP.HCM tổ chức mega livestream bán mai vàng giúp nông dân\n",
      "Added: Đình Bắc không thi đấu trận chia tay giải Đông Nam Á của CLB Công An Hà Nội\n",
      "Added: Bộ GD-ĐT chốt phương án đề thi tốt nghiệp THPT 2026, không công bố đề minh họa\n",
      "\n",
      "Summary: 11 added, 39 duplicates, 0 old\n",
      "✓ Added 11 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 27/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://tuoitre.vn/rss/thoi-su.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 28/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://tuoitre.vn/rss/the-gioi.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 29/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://tuoitre.vn/rss/phap-luat.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 30/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://tuoitre.vn/rss/kinh-doanh.rss\n",
      "Found 50 entries in RSS feed\n",
      "Added: HAGL Agrico do 'đại gia' Trần Bá Dương làm chủ tịch lỗ năm thứ 5 liên tiếp\n",
      "\n",
      "Summary: 1 added, 49 duplicates, 0 old\n",
      "✓ Added 1 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 31/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://tuoitre.vn/rss/giao-duc.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 32/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://tuoitre.vn/rss/the-thao.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 33/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://tuoitre.vn/rss/giai-tri.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 34/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://tuoitre.vn/rss/xe.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 35/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://thanhnien.vn/rss/home.rss\n",
      "Found 60 entries in RSS feed\n",
      "Added: VBF chưa nhận được giấy ủy quyền từ ông Lưu Tú Bảo, vẫn chờ cơ quan chức năng hồ\n",
      "Added: Bắt giữ nghi phạm cướp ngân hàng ở Lào Cai\n",
      "\n",
      "Summary: 2 added, 58 duplicates, 0 old\n",
      "✓ Added 2 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 36/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://thanhnien.vn/rss/thoi-su.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 37/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://thanhnien.vn/rss/the-gioi.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 38/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://thanhnien.vn/rss/kinh-te.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 39/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://thanhnien.vn/rss/van-hoa.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 40/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://thanhnien.vn/rss/the-thao.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 41/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://thanhnien.vn/rss/cong-nghe.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 42/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://thanhnien.vn/rss/gioi-tre.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 43/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vietnamnet.vn/rss/thoi-su.rss\n",
      "Found 1000 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 596 duplicates, 404 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 44/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vietnamnet.vn/rss/the-gioi.rss\n",
      "Found 1000 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 275 duplicates, 725 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 45/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vietnamnet.vn/rss/kinh-doanh.rss\n",
      "Found 1000 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 382 duplicates, 618 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 46/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vietnamnet.vn/rss/giao-duc.rss\n",
      "Found 1000 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 272 duplicates, 728 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 47/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://vietnamnet.vn/rss/the-thao.rss\n",
      "Found 1000 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 555 duplicates, 445 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 48/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://laodong.vn/rss/home.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 49/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://laodong.vn/rss/cong-doan.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 50/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://laodong.vn/rss/xa-hoi.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 51/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://laodong.vn/rss/kinh-doanh.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 52/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://laodong.vn/rss/van-hoa-giai-tri.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 53/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://laodong.vn/rss/xe.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 54/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://laodong.vn/rss/thoi-su.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 55/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://laodong.vn/rss/the-gioi.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 56/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://laodong.vn/rss/phap-luat.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 57/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://laodong.vn/rss/the-thao.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 58/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://laodong.vn/rss/suc-khoe.rss\n",
      "No entries found in RSS feed\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 59/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/home.rss\n",
      "Found 60 entries in RSS feed\n",
      "Added: Khơi thông, huy động các nguồn lực cho phát triển\n",
      "Added: Báo in ngày 5-2: Vỉa hè, hàng rong và sinh kế\n",
      "\n",
      "Summary: 2 added, 58 duplicates, 0 old\n",
      "✓ Added 2 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 60/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/thoi-su.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 61/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/quoc-te.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 62/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/lao-dong.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 63/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/ban-doc.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 64/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/net-zero.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 10 duplicates, 40 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 65/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/kinh-te.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 66/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/suc-khoe.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 67/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/giao-duc-khoa-hoc.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 68/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/phap-luat.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 69/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/van-hoa-van-nghe.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 70/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/giai-tri.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 71/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/the-thao.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 72/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/ai-365.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 27 duplicates, 23 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 73/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/du-lich-xanh.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 34 duplicates, 16 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 74/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/khoa-hoc.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 46 duplicates, 4 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 75/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nld.com.vn/rss/nguoi-lao-dong-news.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 9 duplicates, 41 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 76/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/home.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 77/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/chinhtri-291.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 78/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/thegioi-209.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 79/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/thegioi/asean-356.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 80/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/thegioi/chaua-tbd-352.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 81/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/thegioi/trungdong-230.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 82/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/thegioi/chauau-354.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 83/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/thegioi/chauphi-357.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 18 duplicates, 32 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 84/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/thegioi/chaumy-355.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 85/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/kinhte-311.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 86/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/kinhte/kinhdoanh-342.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 87/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/kinhte/taichinh-343.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 88/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/xahoi-314.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 89/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/xahoi/giaoduc-316.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 90/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/xahoi/yte-325.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 91/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/xahoi/phapluat-327.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 92/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/xahoi/giaothong-358.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 93/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/doisong-320.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 94/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://www.vietnamplus.vn/rss/thethao-214.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 95/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://soha.vn/rss/home.rss\n",
      "Found 60 entries in RSS feed\n",
      "Added: Cô dâu đẹp ma mị đang viral khắp Trung Quốc: Nhan sắc này AI cũng không vẽ nổi, \n",
      "Added: Cố níu giữ người chồng ngoại tình, người mẹ trẻ không ngờ hậu quả lại đổ lên đứa\n",
      "Added: Có thể bạn chưa biết, vào thời La Mã người ta đã sử dụng phân người làm thuốc\n",
      "Added: Phong Phú Hà Nam vô địch sớm Giải nữ U19 Quốc gia 2026\n",
      "Added: Mất tích 20 năm và từng bị liệt vào danh sách tuyệt chủng, tại sao loài dê này l\n",
      "Added: Nhận được quà xịn từ tiệc Tất niên công ty, tôi định gửi về cho bố mẹ đẻ thì chồ\n",
      "Added: Bao nhiêu hy vọng cược cả vào phim Trung Quốc này: Nữ chính là búp bê đẹp nhất t\n",
      "\n",
      "Summary: 7 added, 53 duplicates, 0 old\n",
      "✓ Added 7 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 96/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://soha.vn/rss/thoi-su-xa-hoi.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 97/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://soha.vn/rss/kinh-doanh.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 98/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://soha.vn/rss/quoc-te.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 99/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://soha.vn/rss/the-thao.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 100/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://soha.vn/rss/giai-tri.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 101/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://soha.vn/rss/phap-luat.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 102/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://soha.vn/rss/viet-nam-vuon-minh.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 6 duplicates, 44 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 103/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://soha.vn/rss/sea-games-32.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 0 duplicates, 50 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 104/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/home.rss\n",
      "Found 50 entries in RSS feed\n",
      "Added: Công nhận thêm 30 bảo vật quốc gia\n",
      "\n",
      "Summary: 1 added, 49 duplicates, 0 old\n",
      "✓ Added 1 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 105/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/chinhtri-1171.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 106/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/xa-luan-1176.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 7 duplicates, 43 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 107/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/xay-dung-dang-1179.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 40 duplicates, 10 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 108/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/kinhte-1185.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 109/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/chungkhoan-1191.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 43 duplicates, 7 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 110/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/phapluat-1287.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 111/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/du-lich-1257.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 112/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/thegioi-1231.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 113/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/asean-704471.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 47 duplicates, 3 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 114/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/chau-phi-704476.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 8 duplicates, 42 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 115/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/chau-my-704475.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 30 duplicates, 20 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 116/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/chau-au-704474.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 117/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/trung-dong-704473.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 24 duplicates, 26 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 118/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/chau-a-tbd-704472.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 37 duplicates, 13 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 119/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://nhandan.vn/rss/thethao-1224.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 120/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://baotintuc.vn/tin-moi-nhat.rss\n",
      "Found 10 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 10 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 121/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://baotintuc.vn/thoi-su.rss\n",
      "Found 10 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 10 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 122/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://baotintuc.vn/the-gioi.rss\n",
      "Found 10 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 10 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 123/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://baotintuc.vn/kinh-te.rss\n",
      "Found 10 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 10 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 124/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://baotintuc.vn/xa-hoi.rss\n",
      "Found 10 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 10 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 125/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://baotintuc.vn/phap-luat.rss\n",
      "Found 10 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 10 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 126/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://baotintuc.vn/giao-duc.rss\n",
      "Found 10 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 10 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 127/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://baotintuc.vn/van-hoa.rss\n",
      "Found 10 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 10 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 128/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://baotintuc.vn/the-thao.rss\n",
      "Found 10 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 10 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 129/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://baotintuc.vn/quan-su.rss\n",
      "Found 10 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 10 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 130/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://kienthuc.net.vn/rss/home.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 131/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://kienthuc.net.vn/rss/nha-khoa-hoc-345.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 29 duplicates, 21 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 132/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://kienthuc.net.vn/rss/spotlight-379.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 133/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://kienthuc.net.vn/rss/chinh-tri-348.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 134/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://kienthuc.net.vn/rss/xa-hoi-349.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 135/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://kienthuc.net.vn/rss/the-gioi-350.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 136/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://kienthuc.net.vn/rss/quan-su-359.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "Processing RSS Feed 137/137\n",
      "================================================================================\n",
      "Fetching RSS feed: https://kienthuc.net.vn/rss/giai-tri-365.rss\n",
      "Found 50 entries in RSS feed\n",
      "\n",
      "Summary: 0 added, 50 duplicates, 0 old\n",
      "✓ Added 0 articles from this feed\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Total feeds processed: 137\n",
      "Total articles added: 26\n",
      "Output file: rss_feed_articles_v2.csv\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import hashlib\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Optional, Dict, Any, List, Set, Tuple\n",
    "\n",
    "import requests\n",
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "VN_TZ = timezone(timedelta(hours=7))\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "# Danh sách các RSS feeds từ các báo Việt Nam\n",
    "RSS_FEEDS = [\n",
    "    # VnExpress RSS (15 feeds)\n",
    "    \"https://vnexpress.net/rss/tin-moi-nhat.rss\",\n",
    "    \"https://vnexpress.net/rss/thoi-su.rss\",\n",
    "    \"https://vnexpress.net/rss/the-gioi.rss\",\n",
    "    \"https://vnexpress.net/rss/kinh-doanh.rss\",\n",
    "    \"https://vnexpress.net/rss/giai-tri.rss\",\n",
    "    \"https://vnexpress.net/rss/the-thao.rss\",\n",
    "    \"https://vnexpress.net/rss/phap-luat.rss\",\n",
    "    \"https://vnexpress.net/rss/giao-duc.rss\",\n",
    "    \"https://vnexpress.net/rss/suc-khoe.rss\",\n",
    "    \"https://vnexpress.net/rss/gia-dinh.rss\",\n",
    "    \"https://vnexpress.net/rss/du-lich.rss\",\n",
    "    \"https://vnexpress.net/rss/khoa-hoc.rss\",\n",
    "    \"https://vnexpress.net/rss/so-hoa.rss\",\n",
    "    \"https://vnexpress.net/rss/oto-xe-may.rss\",\n",
    "    \"https://vnexpress.net/rss/y-kien.rss\",\n",
    "    \n",
    "    # Dân Trí RSS (10 feeds)\n",
    "    \"https://dantri.com.vn/rss/trang-chu.rss\",\n",
    "    \"https://dantri.com.vn/rss/xa-hoi.rss\",\n",
    "    \"https://dantri.com.vn/rss/the-gioi.rss\",\n",
    "    \"https://dantri.com.vn/rss/kinh-doanh.rss\",\n",
    "    \"https://dantri.com.vn/rss/the-thao.rss\",\n",
    "    \"https://dantri.com.vn/rss/giai-tri.rss\",\n",
    "    \"https://dantri.com.vn/rss/giao-duc.rss\",\n",
    "    \"https://dantri.com.vn/rss/suc-khoe.rss\",\n",
    "    \"https://dantri.com.vn/rss/du-lich.rss\",\n",
    "    \"https://dantri.com.vn/rss/o-to-xe-may.rss\",\n",
    "    \n",
    "    # Tuổi Trẻ RSS (9 feeds)\n",
    "    \"https://tuoitre.vn/rss/tin-moi-nhat.rss\",\n",
    "    \"https://tuoitre.vn/rss/thoi-su.rss\",\n",
    "    \"https://tuoitre.vn/rss/the-gioi.rss\",\n",
    "    \"https://tuoitre.vn/rss/phap-luat.rss\",\n",
    "    \"https://tuoitre.vn/rss/kinh-doanh.rss\",\n",
    "    \"https://tuoitre.vn/rss/giao-duc.rss\",\n",
    "    \"https://tuoitre.vn/rss/the-thao.rss\",\n",
    "    \"https://tuoitre.vn/rss/giai-tri.rss\",\n",
    "    \"https://tuoitre.vn/rss/xe.rss\",\n",
    "    \n",
    "    # Thanh Niên RSS (8 feeds)\n",
    "    \"https://thanhnien.vn/rss/home.rss\",\n",
    "    \"https://thanhnien.vn/rss/thoi-su.rss\",\n",
    "    \"https://thanhnien.vn/rss/the-gioi.rss\",\n",
    "    \"https://thanhnien.vn/rss/kinh-te.rss\",\n",
    "    \"https://thanhnien.vn/rss/van-hoa.rss\",\n",
    "    \"https://thanhnien.vn/rss/the-thao.rss\",\n",
    "    \"https://thanhnien.vn/rss/cong-nghe.rss\",\n",
    "    \"https://thanhnien.vn/rss/gioi-tre.rss\",\n",
    "    \n",
    "    # VietnamNet RSS (5 feeds)\n",
    "    \"https://vietnamnet.vn/rss/thoi-su.rss\",\n",
    "    \"https://vietnamnet.vn/rss/the-gioi.rss\",\n",
    "    \"https://vietnamnet.vn/rss/kinh-doanh.rss\",\n",
    "    \"https://vietnamnet.vn/rss/giao-duc.rss\",\n",
    "    \"https://vietnamnet.vn/rss/the-thao.rss\",\n",
    "    \n",
    "    # Lao Động RSS (11 feeds)\n",
    "    \"https://laodong.vn/rss/home.rss\",\n",
    "    \"https://laodong.vn/rss/cong-doan.rss\",\n",
    "    \"https://laodong.vn/rss/xa-hoi.rss\",\n",
    "    \"https://laodong.vn/rss/kinh-doanh.rss\",\n",
    "    \"https://laodong.vn/rss/van-hoa-giai-tri.rss\",\n",
    "    \"https://laodong.vn/rss/xe.rss\",\n",
    "    \"https://laodong.vn/rss/thoi-su.rss\",\n",
    "    \"https://laodong.vn/rss/the-gioi.rss\",\n",
    "    \"https://laodong.vn/rss/phap-luat.rss\",\n",
    "    \"https://laodong.vn/rss/the-thao.rss\",\n",
    "    \"https://laodong.vn/rss/suc-khoe.rss\",\n",
    "    \n",
    "    # Người Lao Động RSS (17 feeds)\n",
    "    \"https://nld.com.vn/rss/home.rss\",\n",
    "    \"https://nld.com.vn/rss/thoi-su.rss\",\n",
    "    \"https://nld.com.vn/rss/quoc-te.rss\",\n",
    "    \"https://nld.com.vn/rss/lao-dong.rss\",\n",
    "    \"https://nld.com.vn/rss/ban-doc.rss\",\n",
    "    \"https://nld.com.vn/rss/net-zero.rss\",\n",
    "    \"https://nld.com.vn/rss/kinh-te.rss\",\n",
    "    \"https://nld.com.vn/rss/suc-khoe.rss\",\n",
    "    \"https://nld.com.vn/rss/giao-duc-khoa-hoc.rss\",\n",
    "    \"https://nld.com.vn/rss/phap-luat.rss\",\n",
    "    \"https://nld.com.vn/rss/van-hoa-van-nghe.rss\",\n",
    "    \"https://nld.com.vn/rss/giai-tri.rss\",\n",
    "    \"https://nld.com.vn/rss/the-thao.rss\",\n",
    "    \"https://nld.com.vn/rss/ai-365.rss\",\n",
    "    \"https://nld.com.vn/rss/du-lich-xanh.rss\",\n",
    "    \"https://nld.com.vn/rss/khoa-hoc.rss\",\n",
    "    \"https://nld.com.vn/rss/nguoi-lao-dong-news.rss\",\n",
    "    \n",
    "    # VietnamPlus RSS (19 feeds)\n",
    "    \"https://www.vietnamplus.vn/rss/home.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/chinhtri-291.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/thegioi-209.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/thegioi/asean-356.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/thegioi/chaua-tbd-352.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/thegioi/trungdong-230.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/thegioi/chauau-354.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/thegioi/chauphi-357.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/thegioi/chaumy-355.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/kinhte-311.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/kinhte/kinhdoanh-342.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/kinhte/taichinh-343.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/xahoi-314.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/xahoi/giaoduc-316.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/xahoi/yte-325.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/xahoi/phapluat-327.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/xahoi/giaothong-358.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/doisong-320.rss\",\n",
    "    \"https://www.vietnamplus.vn/rss/thethao-214.rss\",\n",
    "    \n",
    "    # Soha RSS (9 feeds)\n",
    "    \"https://soha.vn/rss/home.rss\",\n",
    "    \"https://soha.vn/rss/thoi-su-xa-hoi.rss\",\n",
    "    \"https://soha.vn/rss/kinh-doanh.rss\",\n",
    "    \"https://soha.vn/rss/quoc-te.rss\",\n",
    "    \"https://soha.vn/rss/the-thao.rss\",\n",
    "    \"https://soha.vn/rss/giai-tri.rss\",\n",
    "    \"https://soha.vn/rss/phap-luat.rss\",\n",
    "    \"https://soha.vn/rss/viet-nam-vuon-minh.rss\",\n",
    "    \"https://soha.vn/rss/sea-games-32.rss\",\n",
    "    \n",
    "    # Nhân Dân RSS (16 feeds)\n",
    "    \"https://nhandan.vn/rss/home.rss\",\n",
    "    \"https://nhandan.vn/rss/chinhtri-1171.rss\",\n",
    "    \"https://nhandan.vn/rss/xa-luan-1176.rss\",\n",
    "    \"https://nhandan.vn/rss/xay-dung-dang-1179.rss\",\n",
    "    \"https://nhandan.vn/rss/kinhte-1185.rss\",\n",
    "    \"https://nhandan.vn/rss/chungkhoan-1191.rss\",\n",
    "    \"https://nhandan.vn/rss/phapluat-1287.rss\",\n",
    "    \"https://nhandan.vn/rss/du-lich-1257.rss\",\n",
    "    \"https://nhandan.vn/rss/thegioi-1231.rss\",\n",
    "    \"https://nhandan.vn/rss/asean-704471.rss\",\n",
    "    \"https://nhandan.vn/rss/chau-phi-704476.rss\",\n",
    "    \"https://nhandan.vn/rss/chau-my-704475.rss\",\n",
    "    \"https://nhandan.vn/rss/chau-au-704474.rss\",\n",
    "    \"https://nhandan.vn/rss/trung-dong-704473.rss\",\n",
    "    \"https://nhandan.vn/rss/chau-a-tbd-704472.rss\",\n",
    "    \"https://nhandan.vn/rss/thethao-1224.rss\",\n",
    "    \n",
    "    # Báo Tin Tức RSS (10 feeds)\n",
    "    \"https://baotintuc.vn/tin-moi-nhat.rss\",\n",
    "    \"https://baotintuc.vn/thoi-su.rss\",\n",
    "    \"https://baotintuc.vn/the-gioi.rss\",\n",
    "    \"https://baotintuc.vn/kinh-te.rss\",\n",
    "    \"https://baotintuc.vn/xa-hoi.rss\",\n",
    "    \"https://baotintuc.vn/phap-luat.rss\",\n",
    "    \"https://baotintuc.vn/giao-duc.rss\",\n",
    "    \"https://baotintuc.vn/van-hoa.rss\",\n",
    "    \"https://baotintuc.vn/the-thao.rss\",\n",
    "    \"https://baotintuc.vn/quan-su.rss\",\n",
    "    \n",
    "    # Kiến Thức RSS (8 feeds)\n",
    "    \"https://kienthuc.net.vn/rss/home.rss\",\n",
    "    \"https://kienthuc.net.vn/rss/nha-khoa-hoc-345.rss\",\n",
    "    \"https://kienthuc.net.vn/rss/spotlight-379.rss\",\n",
    "    \"https://kienthuc.net.vn/rss/chinh-tri-348.rss\",\n",
    "    \"https://kienthuc.net.vn/rss/xa-hoi-349.rss\",\n",
    "    \"https://kienthuc.net.vn/rss/the-gioi-350.rss\",\n",
    "    \"https://kienthuc.net.vn/rss/quan-su-359.rss\",\n",
    "    \"https://kienthuc.net.vn/rss/giai-tri-365.rss\",\n",
    "]\n",
    "\n",
    "# Crawl tất cả bài viết từ RSS feeds\n",
    "END_DATE = \"2026-01-15\"  # YYYY-MM-DD - chỉ lấy bài >= ngày này\n",
    "\n",
    "CSV_PATH = \"rss_feed_articles_v2.csv\"\n",
    "\n",
    "# Có fetch full content từ URL gốc không (chậm hơn nhưng đầy đủ hơn)\n",
    "FETCH_FULL_CONTENT = True\n",
    "\n",
    "TIMEOUT = 25\n",
    "REQUEST_DELAY_BASE = 0.25\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; RSSCrawler/1.0)\",\n",
    "    \"Accept\": \"application/rss+xml, application/xml, text/xml, */*\",\n",
    "}\n",
    "# ===========================================\n",
    "\n",
    "CSV_HEADER = [\n",
    "    \"id\",\n",
    "    \"title\",\n",
    "    \"published_at\",        # ISO UTC\n",
    "    \"source.name\",\n",
    "    \"url\",\n",
    "    \"language\",\n",
    "    \"category.primary\",\n",
    "    \"keywords\",\n",
    "    \"entities\",\n",
    "    \"content.text\",\n",
    "]\n",
    "\n",
    "SOURCE_NAME = \"RSS_Feed\"\n",
    "DEFAULT_LANGUAGE = \"vi\"\n",
    "DEBUG = False\n",
    "\n",
    "# ----- HTTP session with retry -----\n",
    "session = requests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "retry = Retry(\n",
    "    total=6,\n",
    "    connect=6,\n",
    "    read=6,\n",
    "    backoff_factor=0.6,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"GET\", \"HEAD\"],\n",
    "    respect_retry_after_header=True,\n",
    "    raise_on_status=False,\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry, pool_connections=50, pool_maxsize=50)\n",
    "session.mount(\"http://\", adapter)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "\n",
    "def log(msg: str):\n",
    "    if DEBUG:\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "def polite_sleep():\n",
    "    time.sleep(REQUEST_DELAY_BASE)\n",
    "\n",
    "\n",
    "def md5_id(text: str) -> str:\n",
    "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def fetch_text(url: str) -> str:\n",
    "    r = session.get(url, timeout=TIMEOUT, allow_redirects=True)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def ensure_csv_header(csv_path: str):\n",
    "    if not os.path.exists(csv_path) or os.path.getsize(csv_path) == 0:\n",
    "        with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow(CSV_HEADER)\n",
    "\n",
    "\n",
    "def load_seen_from_csv(csv_path: str) -> Tuple[Set[str], Set[str]]:\n",
    "    seen_urls, seen_ids = set(), set()\n",
    "    if not os.path.exists(csv_path):\n",
    "        return seen_urls, seen_ids\n",
    "    try:\n",
    "        with open(csv_path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            r = csv.reader(f)\n",
    "            header = next(r, None)\n",
    "            if not header:\n",
    "                return seen_urls, seen_ids\n",
    "            id_idx = header.index(\"id\") if \"id\" in header else 0\n",
    "            url_idx = header.index(\"url\") if \"url\" in header else 4\n",
    "            for row in r:\n",
    "                if len(row) > url_idx:\n",
    "                    u = row[url_idx].strip()\n",
    "                    if u:\n",
    "                        seen_urls.add(u)\n",
    "                if len(row) > id_idx:\n",
    "                    i = row[id_idx].strip()\n",
    "                    if i:\n",
    "                        seen_ids.add(i)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return seen_urls, seen_ids\n",
    "\n",
    "\n",
    "def append_row(csv_path: str, row: Dict[str, Any]):\n",
    "    with open(csv_path, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([row.get(k, \"\") for k in CSV_HEADER])\n",
    "        f.flush()\n",
    "\n",
    "\n",
    "def iso_to_local_date(iso_utc: str) -> Optional[str]:\n",
    "    if not iso_utc:\n",
    "        return None\n",
    "    try:\n",
    "        dt = datetime.fromisoformat(iso_utc.replace(\"Z\", \"+00:00\"))\n",
    "        if dt.tzinfo is None:\n",
    "            dt = dt.replace(tzinfo=timezone.utc)\n",
    "        return dt.astimezone(VN_TZ).date().isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_rss_date(date_str: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Parse RSS date format to ISO UTC\n",
    "    RSS thường dùng RFC 2822 hoặc ISO format\n",
    "    \"\"\"\n",
    "    if not date_str:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # feedparser tự động parse date\n",
    "        from email.utils import parsedate_to_datetime\n",
    "        dt = parsedate_to_datetime(date_str)\n",
    "        return dt.astimezone(timezone.utc).isoformat()\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Thử ISO format\n",
    "    try:\n",
    "        dt = datetime.fromisoformat(date_str.replace(\"Z\", \"+00:00\"))\n",
    "        if dt.tzinfo is None:\n",
    "            dt = dt.replace(tzinfo=VN_TZ)\n",
    "        return dt.astimezone(timezone.utc).isoformat()\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_category_from_url(url: str) -> Optional[str]:\n",
    "    \"\"\"Trích xuất category từ URL pattern\"\"\"\n",
    "    from urllib.parse import urlparse\n",
    "    \n",
    "    # Mapping các patterns phổ biến\n",
    "    category_map = {\n",
    "        'thoi-su': 'Thời sự',\n",
    "        'the-gioi': 'Thế giới', \n",
    "        'xa-hoi': 'Xã hội',\n",
    "        'kinh-doanh': 'Kinh doanh',\n",
    "        'giai-tri': 'Giải trí',\n",
    "        'the-thao': 'Thể thao',\n",
    "        'phap-luat': 'Pháp luật',\n",
    "        'giao-duc': 'Giáo dục',\n",
    "        'suc-khoe': 'Sức khỏe',\n",
    "        'gia-dinh': 'Gia đình',\n",
    "        'du-lich': 'Du lịch',\n",
    "        'khoa-hoc': 'Khoa học',\n",
    "        'so-hoa': 'Số hóa',\n",
    "        'cong-nghe': 'Công nghệ',\n",
    "        'oto-xe-may': 'Ôtô-Xe máy',\n",
    "        'doi-song': 'Đời sống',\n",
    "        'van-hoa': 'Văn hóa',\n",
    "        'tin-tuc': 'Tin tức',\n",
    "        'video': 'Video',\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        path_parts = [p for p in parsed.path.split('/') if p]\n",
    "        \n",
    "        # Tìm category trong các phần của URL (chỉ xét 2 phần đầu)\n",
    "        for part in path_parts[:2]:\n",
    "            for pattern, category in category_map.items():\n",
    "                if pattern in part:\n",
    "                    return category\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_keywords_from_entry(entry: Any, url: str) -> List[str]:\n",
    "    \"\"\"Trích xuất keywords từ RSS entry và URL\"\"\"\n",
    "    keywords = []\n",
    "    \n",
    "    # 1. Lấy từ tags RSS (Dân Trí, Tuổi Trẻ có field này)\n",
    "    if 'tags' in entry and entry.tags:\n",
    "        for tag in entry.tags:\n",
    "            term = tag.get('term', '').strip()\n",
    "            if term and term not in keywords:\n",
    "                keywords.append(term)\n",
    "    \n",
    "    # 2. Lấy từ category field (nếu không có trong tags)\n",
    "    if 'category' in entry and entry.category:\n",
    "        cat = entry.category.strip()\n",
    "        if cat and cat not in keywords:\n",
    "            keywords.append(cat)\n",
    "    \n",
    "    # 3. Trích xuất từ URL\n",
    "    url_category = extract_category_from_url(url)\n",
    "    if url_category and url_category not in keywords:\n",
    "        keywords.append(url_category)\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "\n",
    "def extract_content_from_html(html_content: str) -> str:\n",
    "    \"\"\"Trích xuất text từ HTML content trong RSS\"\"\"\n",
    "    if not html_content:\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, \"lxml\")\n",
    "        # Lấy tất cả text, loại bỏ tags\n",
    "        text = soup.get_text(separator=\" \", strip=True)\n",
    "        # Làm sạch whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "    except Exception:\n",
    "        return html_content\n",
    "\n",
    "\n",
    "def fetch_article_content(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch nội dung đầy đủ từ URL bài viết\n",
    "    Nếu RSS chỉ có summary, cần fetch trang gốc\n",
    "    \"\"\"\n",
    "    try:\n",
    "        html = fetch_text(url)\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        \n",
    "        # Thử các selector phổ biến\n",
    "        article_body = None\n",
    "        selectors = [\n",
    "            \"article\",\n",
    "            \".article-content\",\n",
    "            \".post-content\",\n",
    "            \".entry-content\",\n",
    "            \".content\",\n",
    "            \"main\",\n",
    "        ]\n",
    "        \n",
    "        for selector in selectors:\n",
    "            article_body = soup.select_one(selector)\n",
    "            if article_body:\n",
    "                break\n",
    "        \n",
    "        if article_body:\n",
    "            paragraphs = article_body.find_all(\"p\")\n",
    "            text_parts = []\n",
    "            for p in paragraphs:\n",
    "                text = p.get_text(strip=True)\n",
    "                if text:\n",
    "                    text_parts.append(text)\n",
    "            return \" \".join(text_parts)\n",
    "        \n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        log(f\"Failed to fetch article content from {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def parse_rss_entry(entry: Any, seen_urls: Set[str], fetch_full_content: bool = False) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Parse một entry từ RSS feed\"\"\"\n",
    "    \n",
    "    # URL\n",
    "    url = entry.get(\"link\", \"\").strip()\n",
    "    if not url or url in seen_urls:\n",
    "        return None\n",
    "    \n",
    "    # Title\n",
    "    title = entry.get(\"title\", \"\").strip()\n",
    "    \n",
    "    # Published date\n",
    "    pub = \"\"\n",
    "    if hasattr(entry, \"published_parsed\") and entry.published_parsed:\n",
    "        try:\n",
    "            dt = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)\n",
    "            pub = dt.isoformat()\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    if not pub and \"published\" in entry:\n",
    "        pub = parse_rss_date(entry.published) or \"\"\n",
    "    \n",
    "    if not pub and \"pubDate\" in entry:\n",
    "        pub = parse_rss_date(entry.pubDate) or \"\"\n",
    "    \n",
    "    # Content\n",
    "    content_text = \"\"\n",
    "    \n",
    "    # Thử lấy content từ RSS\n",
    "    if \"content\" in entry and entry.content:\n",
    "        # feedparser trả về list\n",
    "        content_html = entry.content[0].get(\"value\", \"\") if isinstance(entry.content, list) else entry.content\n",
    "        content_text = extract_content_from_html(content_html)\n",
    "    \n",
    "    # Nếu không có content, thử summary/description\n",
    "    if not content_text:\n",
    "        if \"summary\" in entry:\n",
    "            content_text = extract_content_from_html(entry.summary)\n",
    "        elif \"description\" in entry:\n",
    "            content_text = extract_content_from_html(entry.description)\n",
    "    \n",
    "    # Nếu cần fetch full content từ URL gốc\n",
    "    if fetch_full_content and url:\n",
    "        full_content = fetch_article_content(url)\n",
    "        if full_content and len(full_content) > len(content_text):\n",
    "            content_text = full_content\n",
    "    \n",
    "    # Keywords - tự động trích xuất từ tags RSS hoặc URL\n",
    "    keywords = extract_keywords_from_entry(entry, url)\n",
    "    \n",
    "    # Category - ưu tiên từ tags RSS, sau đó từ URL\n",
    "    category = \"\"\n",
    "    if keywords:\n",
    "        category = keywords[0]  # Lấy keyword đầu tiên làm primary category\n",
    "    \n",
    "    # Author có thể là source\n",
    "    author = entry.get(\"author\", \"\")\n",
    "    \n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"title\": title,\n",
    "        \"published_at\": pub,\n",
    "        \"content_text\": content_text,\n",
    "        \"category\": category,\n",
    "        \"keywords\": keywords,\n",
    "        \"author\": author,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_row(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"id\": md5_id(data[\"url\"]),\n",
    "        \"title\": data.get(\"title\") or \"\",\n",
    "        \"published_at\": data.get(\"published_at\") or \"\",\n",
    "        \"source.name\": data.get(\"author\") or SOURCE_NAME,\n",
    "        \"url\": data[\"url\"],\n",
    "        \"language\": DEFAULT_LANGUAGE,\n",
    "        \"category.primary\": data.get(\"category\") or \"\",\n",
    "        \"keywords\": \"|\".join(data.get(\"keywords\") or []),\n",
    "        \"entities\": \"\",\n",
    "        \"content.text\": data.get(\"content_text\") or \"\",\n",
    "    }\n",
    "\n",
    "\n",
    "def crawl_rss_feed(feed_url: str, end_date: str, seen_urls: Set[str], seen_ids: Set[str], fetch_full_content: bool = False) -> int:\n",
    "    \"\"\"\n",
    "    Crawl RSS feed\n",
    "    fetch_full_content: True nếu muốn fetch nội dung đầy đủ từ URL gốc\n",
    "    \"\"\"\n",
    "    added = 0\n",
    "    skipped_old = 0\n",
    "    skipped_duplicate = 0\n",
    "    \n",
    "    try:\n",
    "        # Parse RSS feed\n",
    "        print(f\"Fetching RSS feed: {feed_url}\")\n",
    "        feed = feedparser.parse(feed_url)\n",
    "        \n",
    "        if not feed.entries:\n",
    "            print(\"No entries found in RSS feed\")\n",
    "            return 0\n",
    "        \n",
    "        print(f\"Found {len(feed.entries)} entries in RSS feed\")\n",
    "        \n",
    "        # Parse end_date\n",
    "        end_dt = datetime.fromisoformat(end_date).replace(tzinfo=VN_TZ)\n",
    "        \n",
    "        for entry in feed.entries:\n",
    "            try:\n",
    "                # Parse entry\n",
    "                data = parse_rss_entry(entry, seen_urls, fetch_full_content=False)\n",
    "                if not data:\n",
    "                    skipped_duplicate += 1\n",
    "                    continue\n",
    "                \n",
    "                # Filter by date\n",
    "                pub_iso = data.get(\"published_at\")\n",
    "                if pub_iso:\n",
    "                    pub_local_date = iso_to_local_date(pub_iso)\n",
    "                    if pub_local_date and pub_local_date < end_date:\n",
    "                        skipped_old += 1\n",
    "                        continue\n",
    "                \n",
    "                # Check duplicate by ID\n",
    "                aid = md5_id(data[\"url\"])\n",
    "                if aid in seen_ids:\n",
    "                    skipped_duplicate += 1\n",
    "                    continue\n",
    "                \n",
    "                # Fetch full content if needed\n",
    "                if fetch_full_content:\n",
    "                    full_content = fetch_article_content(data[\"url\"])\n",
    "                    if full_content and len(full_content) > len(data.get(\"content_text\", \"\")):\n",
    "                        data[\"content_text\"] = full_content\n",
    "                \n",
    "                # Ghi bài vào CSV\n",
    "                row = make_row(data)\n",
    "                append_row(CSV_PATH, row)\n",
    "                seen_urls.add(data[\"url\"])\n",
    "                seen_ids.add(aid)\n",
    "                added += 1\n",
    "                \n",
    "                print(f\"Added: {data.get('title', '')[:80]}\")\n",
    "                \n",
    "                if fetch_full_content:\n",
    "                    polite_sleep()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                log(f\"Error processing entry: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Summary log\n",
    "        print(f\"\\nSummary: {added} added, {skipped_duplicate} duplicates, {skipped_old} old\")\n",
    "        return added\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error crawling RSS feed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    ensure_csv_header(CSV_PATH)\n",
    "    seen_urls, seen_ids = load_seen_from_csv(CSV_PATH)\n",
    "    \n",
    "    total_added = 0\n",
    "    \n",
    "    for i, feed_url in enumerate(RSS_FEEDS, 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing RSS Feed {i}/{len(RSS_FEEDS)}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        try:\n",
    "            added = crawl_rss_feed(feed_url, END_DATE, seen_urls, seen_ids, fetch_full_content=FETCH_FULL_CONTENT)\n",
    "            total_added += added\n",
    "            print(f\"✓ Added {added} articles from this feed\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error with feed {feed_url}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Delay giữa các feeds\n",
    "        if i < len(RSS_FEEDS):\n",
    "            time.sleep(2)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total feeds processed: {len(RSS_FEEDS)}\")\n",
    "    print(f\"Total articles added: {total_added}\")\n",
    "    print(f\"Output file: {CSV_PATH}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c998f22",
   "metadata": {},
   "source": [
    "# lao dong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0bcd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LaoDong HTML crawler...\n",
      "END_DATE: 2026-01-20\n",
      "CSV: laodong_html_articles_vi.csv\n",
      "Categories: 13\n",
      "\n",
      "[thoi-su] Starting crawl...\n",
      "[thoi-su] Fetching page 1: https://laodong.vn/thoi-su/\n",
      "[thoi-su] Page 1: Found 29 candidate articles\n",
      "[thoi-su] Page 1: Added 0 articles (total: 0)\n",
      "[thoi-su] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/thoi-su/] Added 0 articles\n",
      "\n",
      "\n",
      "[the-gioi] Starting crawl...\n",
      "[the-gioi] Fetching page 1: https://laodong.vn/the-gioi/\n",
      "[the-gioi] Page 1: Found 30 candidate articles\n",
      "[the-gioi] Page 1: Added 0 articles (total: 0)\n",
      "[the-gioi] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/the-gioi/] Added 0 articles\n",
      "\n",
      "\n",
      "[xa-hoi] Starting crawl...\n",
      "[xa-hoi] Fetching page 1: https://laodong.vn/xa-hoi/\n",
      "[xa-hoi] Page 1: Found 31 candidate articles\n",
      "[xa-hoi] Page 1: Added 0 articles (total: 0)\n",
      "[xa-hoi] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/xa-hoi/] Added 0 articles\n",
      "\n",
      "\n",
      "[phap-luat] Starting crawl...\n",
      "[phap-luat] Fetching page 1: https://laodong.vn/phap-luat/\n",
      "[phap-luat] Page 1: Found 33 candidate articles\n",
      "[phap-luat] Page 1: Added 0 articles (total: 0)\n",
      "[phap-luat] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/phap-luat/] Added 0 articles\n",
      "\n",
      "\n",
      "[kinh-doanh] Starting crawl...\n",
      "[kinh-doanh] Fetching page 1: https://laodong.vn/kinh-doanh/\n",
      "[kinh-doanh] Page 1: Found 34 candidate articles\n",
      "[kinh-doanh] Page 1: Added 0 articles (total: 0)\n",
      "[kinh-doanh] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/kinh-doanh/] Added 0 articles\n",
      "\n",
      "\n",
      "[bat-dong-san] Starting crawl...\n",
      "[bat-dong-san] Fetching page 1: https://laodong.vn/bat-dong-san/\n",
      "[bat-dong-san] Page 1: Found 34 candidate articles\n",
      "[bat-dong-san] Page 1: Added 0 articles (total: 0)\n",
      "[bat-dong-san] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/bat-dong-san/] Added 0 articles\n",
      "\n",
      "\n",
      "[van-hoa] Starting crawl...\n",
      "[van-hoa] Fetching page 1: https://laodong.vn/van-hoa/\n",
      "[van-hoa] Page 1: Found 38 candidate articles\n",
      "[van-hoa] Page 1: Added 0 articles (total: 0)\n",
      "[van-hoa] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/van-hoa/] Added 0 articles\n",
      "\n",
      "\n",
      "[giao-duc] Starting crawl...\n",
      "[giao-duc] Fetching page 1: https://laodong.vn/giao-duc/\n",
      "[giao-duc] Page 1: Found 34 candidate articles\n",
      "[giao-duc] Page 1: Added 0 articles (total: 0)\n",
      "[giao-duc] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/giao-duc/] Added 0 articles\n",
      "\n",
      "\n",
      "[the-thao] Starting crawl...\n",
      "[the-thao] Fetching page 1: https://laodong.vn/the-thao/\n",
      "[the-thao] Page 1: Found 39 candidate articles\n",
      "[the-thao] Page 1: Added 0 articles (total: 0)\n",
      "[the-thao] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/the-thao/] Added 0 articles\n",
      "\n",
      "\n",
      "[suc-khoe] Starting crawl...\n",
      "[suc-khoe] Fetching page 1: https://laodong.vn/suc-khoe/\n",
      "[suc-khoe] Page 1: Found 38 candidate articles\n",
      "[suc-khoe] Page 1: Added 0 articles (total: 0)\n",
      "[suc-khoe] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/suc-khoe/] Added 0 articles\n",
      "\n",
      "\n",
      "[cong-nghe] Starting crawl...\n",
      "[cong-nghe] Fetching page 1: https://laodong.vn/cong-nghe/\n",
      "[cong-nghe] Page 1: Found 31 candidate articles\n",
      "[cong-nghe] Page 1: Added 0 articles (total: 0)\n",
      "[cong-nghe] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/cong-nghe/] Added 0 articles\n",
      "\n",
      "\n",
      "[xe] Starting crawl...\n",
      "[xe] Fetching page 1: https://laodong.vn/xe/\n",
      "[xe] Page 1: Found 34 candidate articles\n",
      "[xe] Page 1: Added 0 articles (total: 0)\n",
      "[xe] All articles older than 2026-01-20, stopping\n",
      "✓ [https://laodong.vn/xe/] Added 0 articles\n",
      "\n",
      "\n",
      "[du-lich] Starting crawl...\n",
      "[du-lich] Fetching page 1: https://laodong.vn/du-lich/\n",
      "[du-lich] Page 1: No articles found, stopping\n",
      "✓ [https://laodong.vn/du-lich/] Added 0 articles\n",
      "\n",
      "\n",
      "============================================================\n",
      "Done! Total appended 0 rows to laodong_html_articles_vi.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# LaoDong HTML Crawler - Crawl theo category pages với pagination\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import hashlib\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Optional, Dict, Any, List, Set, Tuple\n",
    "from urllib.parse import urlparse, urlencode\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser as dateparser\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "VN_TZ = timezone(timedelta(hours=7))\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "CATEGORY_URLS = [\n",
    "    \"https://laodong.vn/thoi-su/\",\n",
    "    \"https://laodong.vn/the-gioi/\",\n",
    "    \"https://laodong.vn/xa-hoi/\",\n",
    "    \"https://laodong.vn/phap-luat/\",\n",
    "    \"https://laodong.vn/kinh-doanh/\",\n",
    "    \"https://laodong.vn/bat-dong-san/\",\n",
    "    \"https://laodong.vn/van-hoa/\",\n",
    "    \"https://laodong.vn/giao-duc/\",\n",
    "    \"https://laodong.vn/the-thao/\",\n",
    "    \"https://laodong.vn/suc-khoe/\",\n",
    "    \"https://laodong.vn/cong-nghe/\",\n",
    "    \"https://laodong.vn/xe/\",\n",
    "    \"https://laodong.vn/du-lich/\",\n",
    "]\n",
    "\n",
    "# Crawl từ mới -> cũ cho tới khi bài có ngày < END_DATE\n",
    "END_DATE = \"2026-01-20\"  # YYYY-MM-DD - Lấy từ tháng 12/2025 để có nhiều dữ liệu hơn\n",
    "MAX_PAGES_PER_CATEGORY = 100  # Mỗi category tối đa 100 trang\n",
    "\n",
    "CSV_PATH = \"laodong_html_articles_vi.csv\"\n",
    "\n",
    "TIMEOUT = 25\n",
    "REQUEST_DELAY_BASE = 0.3\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "}\n",
    "# ===========================================\n",
    "\n",
    "CSV_HEADER = [\n",
    "    \"id\",\n",
    "    \"title\",\n",
    "    \"published_at\",\n",
    "    \"source.name\",\n",
    "    \"url\",\n",
    "    \"language\",\n",
    "    \"category.primary\",\n",
    "    \"keywords\",\n",
    "    \"entities\",\n",
    "    \"content.text\",\n",
    "]\n",
    "\n",
    "SOURCE_NAME = \"LaoDong\"\n",
    "DEFAULT_LANGUAGE = \"vi\"\n",
    "DEBUG = False\n",
    "\n",
    "# ----- HTTP session with retry -----\n",
    "session = requests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "retry = Retry(\n",
    "    total=6,\n",
    "    connect=6,\n",
    "    read=6,\n",
    "    backoff_factor=0.6,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"GET\", \"HEAD\"],\n",
    "    respect_retry_after_header=True,\n",
    "    raise_on_status=False,\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry, pool_connections=50, pool_maxsize=50)\n",
    "session.mount(\"http://\", adapter)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "\n",
    "def log(msg: str):\n",
    "    if DEBUG:\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "def polite_sleep():\n",
    "    time.sleep(REQUEST_DELAY_BASE + random.uniform(0, 0.4))\n",
    "\n",
    "\n",
    "def md5_id(text: str) -> str:\n",
    "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def fetch_with_cookie_handling(url: str) -> requests.Response:\n",
    "    \"\"\"Fetch URL with laodong.vn cookie protection handling\"\"\"\n",
    "    r = session.get(url, timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    \n",
    "    # Check if response is cookie-setting JavaScript\n",
    "    if \"document.cookie\" in r.text and len(r.content) < 500:\n",
    "        match = re.search(r'document\\.cookie=\"([^\"]+)\"', r.text)\n",
    "        if match:\n",
    "            cookie_str = match.group(1)\n",
    "            cookie_parts = cookie_str.split(\"=\", 1)\n",
    "            if len(cookie_parts) == 2:\n",
    "                cookie_name, cookie_value = cookie_parts\n",
    "                session.cookies.set(cookie_name, cookie_value)\n",
    "                log(f\"[DEBUG] Set cookie: {cookie_name}={cookie_value[:20]}...\")\n",
    "        \n",
    "        polite_sleep()\n",
    "        r = session.get(url, timeout=TIMEOUT)\n",
    "        r.raise_for_status()\n",
    "    \n",
    "    return r\n",
    "\n",
    "\n",
    "def fetch_text(url: str) -> str:\n",
    "    return fetch_with_cookie_handling(url).text\n",
    "\n",
    "\n",
    "def to_iso_utc(s: Optional[str]) -> Optional[str]:\n",
    "    \"\"\"Convert datetime string to ISO UTC format\"\"\"\n",
    "    if not s:\n",
    "        return None\n",
    "    try:\n",
    "        dt = dateparser.parse(s)\n",
    "        if not dt:\n",
    "            return None\n",
    "        if dt.tzinfo is None:\n",
    "            dt = dt.replace(tzinfo=VN_TZ)\n",
    "        return dt.astimezone(timezone.utc).isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def iso_to_local_date(iso_utc: str) -> Optional[str]:\n",
    "    \"\"\"Convert ISO UTC to local date YYYY-MM-DD\"\"\"\n",
    "    if not iso_utc:\n",
    "        return None\n",
    "    try:\n",
    "        dt = dateparser.parse(iso_utc)\n",
    "        if not dt:\n",
    "            return None\n",
    "        if dt.tzinfo is None:\n",
    "            dt = dt.replace(tzinfo=timezone.utc)\n",
    "        dt_local = dt.astimezone(VN_TZ)\n",
    "        return dt_local.date().isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def ensure_csv_header(csv_path: str):\n",
    "    if not os.path.exists(csv_path) or os.path.getsize(csv_path) == 0:\n",
    "        with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow(CSV_HEADER)\n",
    "\n",
    "\n",
    "def load_seen_from_csv(csv_path: str) -> Tuple[Set[str], Set[str]]:\n",
    "    seen_urls, seen_ids = set(), set()\n",
    "    if not os.path.exists(csv_path):\n",
    "        return seen_urls, seen_ids\n",
    "    try:\n",
    "        with open(csv_path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            r = csv.reader(f)\n",
    "            header = next(r, None)\n",
    "            if not header:\n",
    "                return seen_urls, seen_ids\n",
    "            id_idx = header.index(\"id\") if \"id\" in header else 0\n",
    "            url_idx = header.index(\"url\") if \"url\" in header else 4\n",
    "            for row in r:\n",
    "                if len(row) > url_idx:\n",
    "                    u = row[url_idx].strip()\n",
    "                    if u:\n",
    "                        seen_urls.add(u)\n",
    "                if len(row) > id_idx:\n",
    "                    i = row[id_idx].strip()\n",
    "                    if i:\n",
    "                        seen_ids.add(i)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return seen_urls, seen_ids\n",
    "\n",
    "\n",
    "def append_row(csv_path: str, row: Dict[str, Any]):\n",
    "    with open(csv_path, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([row.get(k, \"\") for k in CSV_HEADER])\n",
    "        f.flush()\n",
    "\n",
    "\n",
    "def extract_article_meta(article_html: str) -> Dict[str, Any]:\n",
    "    soup = BeautifulSoup(article_html, \"lxml\")\n",
    "\n",
    "    # title\n",
    "    title = \"\"\n",
    "    og = soup.select_one('meta[property=\"og:title\"]')\n",
    "    if og and og.get(\"content\"):\n",
    "        title = og[\"content\"].strip()\n",
    "    if not title:\n",
    "        h1 = soup.select_one(\"h1\")\n",
    "        if h1:\n",
    "            title = h1.get_text(strip=True)\n",
    "\n",
    "    # published_at\n",
    "    pub = \"\"\n",
    "    m_pub = soup.select_one('meta[property=\"article:published_time\"]')\n",
    "    if m_pub and m_pub.get(\"content\"):\n",
    "        pub = to_iso_utc(m_pub[\"content\"].strip()) or \"\"\n",
    "    if not pub:\n",
    "        m2 = soup.select_one('meta[itemprop=\"datePublished\"]')\n",
    "        if m2 and m2.get(\"content\"):\n",
    "            pub = to_iso_utc(m2[\"content\"].strip()) or \"\"\n",
    "    if not pub:\n",
    "        ttag = soup.select_one(\"time\")\n",
    "        if ttag:\n",
    "            pub = to_iso_utc(ttag.get(\"datetime\") or ttag.get_text(strip=True)) or \"\"\n",
    "\n",
    "    # category\n",
    "    category_primary = \"\"\n",
    "    sec = soup.select_one('meta[property=\"article:section\"]')\n",
    "    if sec and sec.get(\"content\"):\n",
    "        category_primary = sec[\"content\"].strip()\n",
    "\n",
    "    # language\n",
    "    language = DEFAULT_LANGUAGE\n",
    "    html_tag = soup.find(\"html\")\n",
    "    if html_tag:\n",
    "        lang = html_tag.get(\"lang\")\n",
    "        if lang:\n",
    "            language = lang.lower().strip()\n",
    "\n",
    "    # keywords\n",
    "    keywords = []\n",
    "    kw = soup.select_one('meta[name=\"keywords\"]')\n",
    "    if kw and kw.get(\"content\"):\n",
    "        keywords = [x.strip() for x in kw[\"content\"].split(\",\") if x.strip()]\n",
    "\n",
    "    # content.text\n",
    "    content_text = \"\"\n",
    "    article_body = soup.select_one(\"article.detail-content\")\n",
    "    if not article_body:\n",
    "        article_body = soup.select_one(\".detail-content\")\n",
    "    if not article_body:\n",
    "        article_body = soup.select_one(\"article\")\n",
    "    \n",
    "    if article_body:\n",
    "        paragraphs = article_body.find_all(\"p\")\n",
    "        text_parts = []\n",
    "        for p in paragraphs:\n",
    "            text = p.get_text(strip=True)\n",
    "            if text:\n",
    "                text_parts.append(text)\n",
    "        content_text = \" \".join(text_parts)\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"published_at\": pub,\n",
    "        \"language\": language,\n",
    "        \"keywords\": keywords,\n",
    "        \"category_from_article\": category_primary,\n",
    "        \"entities\": [],\n",
    "        \"content_text\": content_text,\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_article_urls_from_page(html: str, category_url: str) -> List[str]:\n",
    "    \"\"\"Extract article URLs from category page\"\"\"\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    urls = []\n",
    "    \n",
    "    # LaoDong uses various link patterns\n",
    "    for a in soup.select(\"a[href]\"):\n",
    "        href = a.get(\"href\", \"\").strip()\n",
    "        if not href:\n",
    "            continue\n",
    "        \n",
    "        # Make absolute URL\n",
    "        if href.startswith(\"/\"):\n",
    "            href = \"https://laodong.vn\" + href\n",
    "        \n",
    "        # Only laodong.vn articles\n",
    "        if not href.startswith(\"https://laodong.vn/\"):\n",
    "            continue\n",
    "        \n",
    "        # Article URLs end with .ldo\n",
    "        if not href.endswith(\".ldo\"):\n",
    "            continue\n",
    "        \n",
    "        # Remove query params\n",
    "        href = href.split(\"?\")[0]\n",
    "        urls.append(href)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for u in urls:\n",
    "        if u not in seen:\n",
    "            seen.add(u)\n",
    "            result.append(u)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_next_page_url(category_url: str, page: int) -> str:\n",
    "    \"\"\"\n",
    "    LaoDong pagination: ?page=2, ?page=3, etc.\n",
    "    \"\"\"\n",
    "    base_url = category_url.rstrip(\"/\")\n",
    "    return f\"{base_url}?page={page}\"\n",
    "\n",
    "\n",
    "def make_row(url: str, meta: Dict[str, Any], category_fallback: str) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"id\": md5_id(url),\n",
    "        \"title\": meta.get(\"title\") or \"\",\n",
    "        \"published_at\": meta.get(\"published_at\") or \"\",\n",
    "        \"source.name\": SOURCE_NAME,\n",
    "        \"url\": url,\n",
    "        \"language\": meta.get(\"language\") or DEFAULT_LANGUAGE,\n",
    "        \"category.primary\": (meta.get(\"category_from_article\") or category_fallback) or \"\",\n",
    "        \"keywords\": \"|\".join(meta.get(\"keywords\") or []),\n",
    "        \"entities\": \"|\".join(meta.get(\"entities\") or []),\n",
    "        \"content.text\": meta.get(\"content_text\") or \"\",\n",
    "    }\n",
    "\n",
    "\n",
    "def category_slug_from_url(url: str) -> str:\n",
    "    \"\"\"Extract category slug from URL\"\"\"\n",
    "    path = urlparse(url).path.strip(\"/\")\n",
    "    return path.split(\"/\")[0] if \"/\" in path else path\n",
    "\n",
    "\n",
    "def crawl_category(category_url: str, end_date: str, seen_urls: Set[str], seen_ids: Set[str]) -> Tuple[int, int, int]:\n",
    "    \"\"\"\n",
    "    Crawl one category from new to old until < end_date\n",
    "    Returns: (added, skipped_duplicate, skipped_old)\n",
    "    \"\"\"\n",
    "    added = 0\n",
    "    skipped_duplicate = 0\n",
    "    skipped_old = 0\n",
    "    page = 1\n",
    "    category_slug = category_slug_from_url(category_url)\n",
    "    \n",
    "    print(f\"\\n[{category_slug}] Starting crawl...\")\n",
    "    \n",
    "    while page <= MAX_PAGES_PER_CATEGORY:\n",
    "        # Page 1 is the category URL, page 2+ use ?page=N\n",
    "        if page == 1:\n",
    "            url_page = category_url\n",
    "        else:\n",
    "            url_page = get_next_page_url(category_url, page)\n",
    "        \n",
    "        print(f\"[{category_slug}] Fetching page {page}: {url_page}\")\n",
    "        \n",
    "        try:\n",
    "            html = fetch_text(url_page)\n",
    "        except Exception as e:\n",
    "            print(f\"[{category_slug}] Page {page} fetch failed: {e}\")\n",
    "            break\n",
    "        \n",
    "        article_urls = extract_article_urls_from_page(html, category_url)\n",
    "        \n",
    "        if not article_urls:\n",
    "            print(f\"[{category_slug}] Page {page}: No articles found, stopping\")\n",
    "            break\n",
    "        \n",
    "        print(f\"[{category_slug}] Page {page}: Found {len(article_urls)} candidate articles\")\n",
    "        \n",
    "        page_all_older_than_end = True\n",
    "        page_added = 0\n",
    "        \n",
    "        for aurl in article_urls:\n",
    "            if aurl in seen_urls:\n",
    "                continue\n",
    "            \n",
    "            aid = md5_id(aurl)\n",
    "            if aid in seen_ids:\n",
    "                continue\n",
    "            \n",
    "            # Fetch article\n",
    "            try:\n",
    "                ah = fetch_text(aurl)\n",
    "                meta = extract_article_meta(ah)\n",
    "            except Exception as e:\n",
    "                log(f\"[WARN] Article fetch failed {aurl}: {e}\")\n",
    "                continue\n",
    "            finally:\n",
    "                polite_sleep()\n",
    "            \n",
    "            pub_iso = meta.get(\"published_at\") or \"\"\n",
    "            pub_local_date = iso_to_local_date(pub_iso) or \"\"\n",
    "            \n",
    "            # Check if article is old enough to stop\n",
    "            if pub_local_date and pub_local_date < end_date:\n",
    "                pass  # Bài cũ, không ghi\n",
    "            else:\n",
    "                page_all_older_than_end = False\n",
    "            \n",
    "            # Only save articles >= end_date\n",
    "            if (not pub_local_date) or (pub_local_date >= end_date):\n",
    "                row = make_row(aurl, meta, category_fallback=category_slug)\n",
    "                append_row(CSV_PATH, row)\n",
    "                seen_urls.add(aurl)\n",
    "                seen_ids.add(aid)\n",
    "                added += 1\n",
    "                page_added += 1\n",
    "        \n",
    "        print(f\"[{category_slug}] Page {page}: Added {page_added} articles (total: {added})\")\n",
    "        \n",
    "        # Stop if all articles on this page are older than end_date\n",
    "        if page_all_older_than_end:\n",
    "            print(f\"[{category_slug}] All articles older than {end_date}, stopping\")\n",
    "            break\n",
    "        \n",
    "        page += 1\n",
    "        polite_sleep()\n",
    "    \n",
    "    return added\n",
    "\n",
    "\n",
    "def main():\n",
    "    ensure_csv_header(CSV_PATH)\n",
    "    seen_urls, seen_ids = load_seen_from_csv(CSV_PATH)\n",
    "    \n",
    "    print(f\"Starting LaoDong HTML crawler...\")\n",
    "    print(f\"END_DATE: {END_DATE}\")\n",
    "    print(f\"CSV: {CSV_PATH}\")\n",
    "    print(f\"Categories: {len(CATEGORY_URLS)}\")\n",
    "    \n",
    "    total = 0\n",
    "    for cat in CATEGORY_URLS:\n",
    "        try:\n",
    "            added = crawl_category(cat, END_DATE, seen_urls, seen_ids)\n",
    "            print(f\"✓ [{cat}] Added {added} articles\\n\")\n",
    "            total += added\n",
    "        except Exception as e:\n",
    "            print(f\"✗ [{cat}] ERROR: {e}\\n\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Done! Total appended {total} rows to {CSV_PATH}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570062ca",
   "metadata": {},
   "source": [
    "# znews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd50e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZNews Crawler - Cơ chế xử lý Duplicate ===\n",
      "Đã load 3013 URLs và 3013 IDs từ CSV\n",
      "END_DATE: 2026-01-15\n",
      "Crawling 7 categories...\n",
      "\n",
      "[https://znews.vn/xuat-ban.html]\n",
      "  ✅ Added: 0 bài mới\n",
      "  🔄 Duplicates: 50 bài trùng\n",
      "  ⏰ Old: 6 bài cũ (< 2026-01-15)\n",
      "  📊 Duplicate rate: 89.3%\n",
      "\n",
      "[https://znews.vn/kinh-doanh-tai-chinh.html]\n",
      "  ✅ Added: 0 bài mới\n",
      "  🔄 Duplicates: 60 bài trùng\n",
      "  ⏰ Old: 6 bài cũ (< 2026-01-15)\n",
      "  📊 Duplicate rate: 90.9%\n",
      "\n",
      "[https://znews.vn/suc-khoe.html]\n",
      "  ✅ Added: 0 bài mới\n",
      "  🔄 Duplicates: 57 bài trùng\n",
      "  ⏰ Old: 14 bài cũ (< 2026-01-15)\n",
      "  📊 Duplicate rate: 80.3%\n",
      "\n",
      "[https://znews.vn/the-thao.html]\n",
      "  ✅ Added: 0 bài mới\n",
      "  🔄 Duplicates: 53 bài trùng\n",
      "  ⏰ Old: 3 bài cũ (< 2026-01-15)\n",
      "  📊 Duplicate rate: 94.6%\n",
      "\n",
      "[https://znews.vn/doi-song.html]\n",
      "  ✅ Added: 0 bài mới\n",
      "  🔄 Duplicates: 58 bài trùng\n",
      "  ⏰ Old: 15 bài cũ (< 2026-01-15)\n",
      "  📊 Duplicate rate: 79.5%\n",
      "\n",
      "[https://znews.vn/cong-nghe.html]\n",
      "  ✅ Added: 0 bài mới\n",
      "  🔄 Duplicates: 50 bài trùng\n",
      "  ⏰ Old: 3 bài cũ (< 2026-01-15)\n",
      "  📊 Duplicate rate: 94.3%\n",
      "\n",
      "[https://znews.vn/giai-tri.html]\n",
      "  ✅ Added: 0 bài mới\n",
      "  🔄 Duplicates: 51 bài trùng\n",
      "  ⏰ Old: 17 bài cũ (< 2026-01-15)\n",
      "  📊 Duplicate rate: 75.0%\n",
      "\n",
      "\n",
      "============================================================\n",
      "📈 TỔNG KẾT:\n",
      "  ✅ Tổng bài mới thêm vào CSV: 0\n",
      "  🔄 Tổng bài trùng (bỏ qua): 379\n",
      "  ⏰ Tổng bài cũ (bỏ qua): 64\n",
      "  📊 Tổng bài kiểm tra: 443\n",
      "  💯 Tỷ lệ duplicate: 85.6%\n",
      "============================================================\n",
      "\n",
      "✅ Hoàn thành! Đã thêm 0 bài mới vào znews_html_categories_vi.csv\n",
      "💡 Gợi ý: Tỷ lệ duplicate cao (85.6%) cho thấy crawler đang hoạt động tốt!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import hashlib\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Optional, Dict, Any, List, Set, Tuple\n",
    "from urllib.parse import urlparse, urlunparse, parse_qs, urlencode\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser as dateparser\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "VN_TZ = timezone(timedelta(hours=7))\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "CATEGORY_URLS = [\n",
    "    \"https://znews.vn/xuat-ban.html\",\n",
    "    \"https://znews.vn/kinh-doanh-tai-chinh.html\",\n",
    "    \"https://znews.vn/suc-khoe.html\",\n",
    "    \"https://znews.vn/the-thao.html\",\n",
    "    \"https://znews.vn/doi-song.html\",\n",
    "    \"https://znews.vn/cong-nghe.html\",\n",
    "    \"https://znews.vn/giai-tri.html\",\n",
    "]\n",
    "\n",
    "# Crawl từ mới -> cũ cho tới khi bài có ngày < END_DATE (theo giờ VN)\n",
    "END_DATE = \"2026-01-15\"  # YYYY-MM-DD\n",
    "MAX_PAGES_PER_CATEGORY = 2000  # safety stop\n",
    "\n",
    "CSV_PATH = \"znews_html_categories_vi.csv\"\n",
    "\n",
    "TIMEOUT = 25\n",
    "REQUEST_DELAY_BASE = 0.25\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; ZNewsHTMLCrawler/1.0)\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "}\n",
    "# ===========================================\n",
    "\n",
    "CSV_HEADER = [\n",
    "    \"id\",\n",
    "    \"title\",\n",
    "    \"published_at\",\n",
    "    \"source.name\",\n",
    "    \"url\",\n",
    "    \"language\",\n",
    "    \"category.primary\",\n",
    "    \"keywords\",\n",
    "    \"entities\",\n",
    "    \"content.text\",\n",
    "]\n",
    "\n",
    "SOURCE_NAME = \"ZNews\"\n",
    "DEFAULT_LANGUAGE = \"vi\"\n",
    "DEBUG = False\n",
    "\n",
    "# ----- HTTP session with retry -----\n",
    "session = requests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "retry = Retry(\n",
    "    total=6,\n",
    "    connect=6,\n",
    "    read=6,\n",
    "    backoff_factor=0.6,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"GET\", \"HEAD\"],\n",
    "    respect_retry_after_header=True,\n",
    "    raise_on_status=False,\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry, pool_connections=50, pool_maxsize=50)\n",
    "session.mount(\"http://\", adapter)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "\n",
    "def log(msg: str):\n",
    "    if DEBUG:\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "def polite_sleep():\n",
    "    time.sleep(REQUEST_DELAY_BASE + random.uniform(0, 0.4))\n",
    "\n",
    "\n",
    "def md5_id(text: str) -> str:\n",
    "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def fetch_text(url: str) -> str:\n",
    "    r = session.get(url, timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def to_iso_utc(s: Optional[str]) -> Optional[str]:\n",
    "    if not s:\n",
    "        return None\n",
    "    try:\n",
    "        dt = dateparser.parse(s)\n",
    "        if not dt:\n",
    "            return None\n",
    "        if dt.tzinfo is None:\n",
    "            if VN_TZ:\n",
    "                dt = dt.replace(tzinfo=VN_TZ)\n",
    "            else:\n",
    "                dt = dt.replace(tzinfo=timezone.utc)\n",
    "        return dt.astimezone(timezone.utc).isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def iso_to_local_date(iso_utc: str) -> Optional[str]:\n",
    "    if not iso_utc:\n",
    "        return None\n",
    "    try:\n",
    "        dt = dateparser.parse(iso_utc)\n",
    "        if not dt:\n",
    "            return None\n",
    "        if dt.tzinfo is None:\n",
    "            dt = dt.replace(tzinfo=timezone.utc)\n",
    "        if VN_TZ:\n",
    "            dt_local = dt.astimezone(VN_TZ)\n",
    "        else:\n",
    "            dt_local = dt\n",
    "        return dt_local.date().isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def ensure_csv_header(csv_path: str):\n",
    "    if not os.path.exists(csv_path) or os.path.getsize(csv_path) == 0:\n",
    "        with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow(CSV_HEADER)\n",
    "\n",
    "\n",
    "def load_seen_from_csv(csv_path: str) -> Tuple[Set[str], Set[str]]:\n",
    "    seen_urls, seen_ids = set(), set()\n",
    "    if not os.path.exists(csv_path):\n",
    "        return seen_urls, seen_ids\n",
    "    try:\n",
    "        with open(csv_path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            r = csv.reader(f)\n",
    "            header = next(r, None)\n",
    "            if not header:\n",
    "                return seen_urls, seen_ids\n",
    "            id_idx = header.index(\"id\") if \"id\" in header else 0\n",
    "            url_idx = header.index(\"url\") if \"url\" in header else 4\n",
    "            for row in r:\n",
    "                if len(row) > url_idx:\n",
    "                    u = row[url_idx].strip()\n",
    "                    if u:\n",
    "                        seen_urls.add(u)\n",
    "                if len(row) > id_idx:\n",
    "                    i = row[id_idx].strip()\n",
    "                    if i:\n",
    "                        seen_ids.add(i)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return seen_urls, seen_ids\n",
    "\n",
    "\n",
    "def append_row(csv_path: str, row: Dict[str, Any]):\n",
    "    with open(csv_path, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([row.get(k, \"\") for k in CSV_HEADER])\n",
    "        f.flush()\n",
    "\n",
    "\n",
    "def extract_language_from_html(soup: BeautifulSoup) -> str:\n",
    "    html_tag = soup.find(\"html\")\n",
    "    if html_tag:\n",
    "        lang = html_tag.get(\"lang\") or html_tag.get(\"xml:lang\")\n",
    "        if lang:\n",
    "            lang = lang.lower().strip()\n",
    "            if lang.startswith(\"vi\"):\n",
    "                return \"vi\"\n",
    "            if lang.startswith(\"en\"):\n",
    "                return \"en\"\n",
    "            return lang\n",
    "    return DEFAULT_LANGUAGE\n",
    "\n",
    "\n",
    "def extract_keywords_from_html(soup: BeautifulSoup) -> List[str]:\n",
    "    for sel in ['meta[name=\"keywords\"]', 'meta[name=\"news_keywords\"]']:\n",
    "        tag = soup.select_one(sel)\n",
    "        if tag and tag.get(\"content\"):\n",
    "            raw = tag[\"content\"]\n",
    "            kws = [x.strip() for x in raw.split(\",\") if x.strip()]\n",
    "            seen = set()\n",
    "            out = []\n",
    "            for k in kws:\n",
    "                if k not in seen:\n",
    "                    seen.add(k)\n",
    "                    out.append(k)\n",
    "            return out\n",
    "    return []\n",
    "\n",
    "\n",
    "def extract_article_meta(article_html: str) -> Dict[str, Any]:\n",
    "    soup = BeautifulSoup(article_html, \"lxml\")\n",
    "\n",
    "    # title\n",
    "    title = \"\"\n",
    "    og = soup.select_one('meta[property=\"og:title\"]')\n",
    "    if og and og.get(\"content\"):\n",
    "        title = og[\"content\"].strip()\n",
    "    if not title:\n",
    "        h1 = soup.select_one(\"h1.title-detail, h1.article-title, h1\")\n",
    "        if h1:\n",
    "            title = h1.get_text(strip=True)\n",
    "\n",
    "    # published_at\n",
    "    pub = \"\"\n",
    "    m_pub = soup.select_one('meta[property=\"article:published_time\"]')\n",
    "    if m_pub and m_pub.get(\"content\"):\n",
    "        pub = to_iso_utc(m_pub[\"content\"].strip()) or \"\"\n",
    "    if not pub:\n",
    "        m2 = soup.select_one('meta[itemprop=\"datePublished\"]')\n",
    "        if m2 and m2.get(\"content\"):\n",
    "            pub = to_iso_utc(m2[\"content\"].strip()) or \"\"\n",
    "    if not pub:\n",
    "        ttag = soup.select_one(\"time\")\n",
    "        if ttag:\n",
    "            pub = to_iso_utc(ttag.get(\"datetime\") or ttag.get_text(strip=True)) or \"\"\n",
    "\n",
    "    # category.primary\n",
    "    category_primary = \"\"\n",
    "    sec = soup.select_one('meta[property=\"article:section\"]')\n",
    "    if sec and sec.get(\"content\"):\n",
    "        category_primary = sec[\"content\"].strip()\n",
    "\n",
    "    language = extract_language_from_html(soup)\n",
    "    keywords = extract_keywords_from_html(soup)\n",
    "\n",
    "    # content.text - ZNews thường dùng class .article-body, .the-article-body\n",
    "    content_text = \"\"\n",
    "    article_body = soup.select_one(\".the-article-body\")\n",
    "    if not article_body:\n",
    "        article_body = soup.select_one(\".article-body\")\n",
    "    if not article_body:\n",
    "        article_body = soup.select_one(\"article\")\n",
    "    if not article_body:\n",
    "        article_body = soup.select_one(\".content-detail\")\n",
    "    \n",
    "    if article_body:\n",
    "        paragraphs = article_body.find_all(\"p\")\n",
    "        text_parts = []\n",
    "        for p in paragraphs:\n",
    "            text = p.get_text(strip=True)\n",
    "            if text:\n",
    "                text_parts.append(text)\n",
    "        content_text = \" \".join(text_parts)\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"published_at\": pub,\n",
    "        \"language\": language,\n",
    "        \"keywords\": keywords,\n",
    "        \"category_from_article\": category_primary,\n",
    "        \"entities\": [],\n",
    "        \"content_text\": content_text,\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_article_urls_from_category_page(html: str) -> List[str]:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    urls = []\n",
    "    for a in soup.select(\"a[href]\"):\n",
    "        href = a.get(\"href\", \"\").strip()\n",
    "        if not href:\n",
    "            continue\n",
    "        if href.startswith(\"/\"):\n",
    "            href = \"https://znews.vn\" + href\n",
    "        if not href.startswith(\"https://znews.vn/\"):\n",
    "            continue\n",
    "        # ZNews bài viết thường có format /ten-bai-post[ID].html\n",
    "        if \"-post\" in href and \".html\" in href:\n",
    "            urls.append(href.split(\"?\")[0])\n",
    "\n",
    "    # unique giữ thứ tự\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for u in urls:\n",
    "        if u not in seen:\n",
    "            seen.add(u)\n",
    "            out.append(u)\n",
    "    return out\n",
    "\n",
    "\n",
    "def find_next_page_url(category_url: str, html: str, current_page: int) -> Optional[str]:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    # thử rel=next\n",
    "    ln = soup.select_one('link[rel=\"next\"]')\n",
    "    if ln and ln.get(\"href\"):\n",
    "        href = ln[\"href\"].strip()\n",
    "        if href.startswith(\"/\"):\n",
    "            href = \"https://znews.vn\" + href\n",
    "        return href\n",
    "\n",
    "    # thử tìm nút pagination\n",
    "    a_next = soup.select_one('a.page-next, a[rel=\"next\"]')\n",
    "    if a_next and a_next.get(\"href\"):\n",
    "        href = a_next[\"href\"].strip()\n",
    "        if href.startswith(\"/\"):\n",
    "            href = \"https://znews.vn\" + href\n",
    "        return href\n",
    "\n",
    "    # fallback: ZNews dùng format /trangX.html\n",
    "    # https://znews.vn/the-thao.html -> https://znews.vn/the-thao/trang2.html\n",
    "    next_page = current_page + 1\n",
    "    base_url = category_url.rstrip(\"/\").replace(\".html\", \"\")\n",
    "    return f\"{base_url}/trang{next_page}.html\"\n",
    "\n",
    "\n",
    "def make_row(url: str, meta: Dict[str, Any], category_fallback: str) -> Dict[str, Any]:\n",
    "    id_ = md5_id(url)\n",
    "    category_primary = meta.get(\"category_from_article\") or category_fallback\n",
    "    keywords_str = \"|\".join(meta.get(\"keywords\") or [])\n",
    "    entities_str = \"|\".join(meta.get(\"entities\") or [])\n",
    "\n",
    "    return {\n",
    "        \"id\": id_,\n",
    "        \"title\": meta.get(\"title\") or \"\",\n",
    "        \"published_at\": meta.get(\"published_at\") or \"\",\n",
    "        \"source.name\": SOURCE_NAME,\n",
    "        \"url\": url,\n",
    "        \"language\": meta.get(\"language\") or DEFAULT_LANGUAGE,\n",
    "        \"category.primary\": category_primary or \"\",\n",
    "        \"keywords\": keywords_str,\n",
    "        \"entities\": entities_str,\n",
    "        \"content.text\": meta.get(\"content_text\") or \"\",\n",
    "    }\n",
    "\n",
    "\n",
    "def crawl_category(category_url: str, end_date: str, seen_urls: Set[str], seen_ids: Set[str]) -> Tuple[int, int, int]:\n",
    "    \"\"\"\n",
    "    Crawl category và trả về (added, skipped_duplicate, skipped_old)\n",
    "    - added: số bài mới được thêm vào CSV\n",
    "    - skipped_duplicate: số bài bị trùng (đã có trong CSV)\n",
    "    - skipped_old: số bài cũ hơn END_DATE\n",
    "    \"\"\"\n",
    "    added = 0\n",
    "    skipped_duplicate = 0\n",
    "    skipped_old = 0\n",
    "    page = 1\n",
    "    url_page = category_url\n",
    "\n",
    "    # extract category slug từ URL\n",
    "    category_slug = category_url.rstrip(\"/\").split(\"/\")[-1].replace(\".html\", \"\")\n",
    "\n",
    "    while page <= MAX_PAGES_PER_CATEGORY and url_page:\n",
    "        html = fetch_text(url_page)\n",
    "        article_urls = extract_article_urls_from_category_page(html)\n",
    "\n",
    "        if DEBUG:\n",
    "            log(f\"[{category_slug}] page {page} got {len(article_urls)} candidate urls: {url_page}\")\n",
    "\n",
    "        if not article_urls:\n",
    "            break\n",
    "\n",
    "        page_all_older_than_end = True\n",
    "\n",
    "        for aurl in article_urls:\n",
    "            # Kiểm tra duplicate TRƯỚC KHI fetch HTML\n",
    "            if aurl in seen_urls:\n",
    "                skipped_duplicate += 1\n",
    "                continue\n",
    "\n",
    "            aid = md5_id(aurl)\n",
    "            if aid in seen_ids:\n",
    "                skipped_duplicate += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                ah = fetch_text(aurl)\n",
    "                meta = extract_article_meta(ah)\n",
    "            except Exception as e:\n",
    "                log(f\"[WARN] article fetch failed {aurl}: {e}\")\n",
    "                continue\n",
    "            finally:\n",
    "                polite_sleep()\n",
    "\n",
    "            pub_iso = meta.get(\"published_at\") or \"\"\n",
    "            pub_local_date = iso_to_local_date(pub_iso) or \"\"\n",
    "\n",
    "            # nếu có ngày và nhỏ hơn end_date => đánh dấu cũ\n",
    "            if pub_local_date and pub_local_date < end_date:\n",
    "                skipped_old += 1\n",
    "                pass\n",
    "            else:\n",
    "                page_all_older_than_end = False\n",
    "\n",
    "            # Nếu bài >= end_date thì ghi\n",
    "            if (not pub_local_date) or (pub_local_date >= end_date):\n",
    "                row = make_row(aurl, meta, category_fallback=category_slug)\n",
    "                append_row(CSV_PATH, row)\n",
    "                seen_urls.add(aurl)\n",
    "                seen_ids.add(aid)\n",
    "                added += 1\n",
    "\n",
    "        # Nếu cả trang toàn bài cũ hơn end_date thì dừng category này\n",
    "        if page_all_older_than_end:\n",
    "            if DEBUG:\n",
    "                log(f\"[{category_slug}] stop: page {page} all older than end_date={end_date}\")\n",
    "            break\n",
    "\n",
    "        # đi trang tiếp\n",
    "        next_url = find_next_page_url(category_url, html, current_page=page)\n",
    "        if not next_url or next_url == url_page:\n",
    "            break\n",
    "        if next_url == url_page:\n",
    "            break\n",
    "        url_page = next_url\n",
    "        page += 1\n",
    "        polite_sleep()\n",
    "\n",
    "    return added, skipped_duplicate, skipped_old\n",
    "\n",
    "\n",
    "def main():\n",
    "    ensure_csv_header(CSV_PATH)\n",
    "    seen_urls, seen_ids = load_seen_from_csv(CSV_PATH)\n",
    "\n",
    "    print(f\"=== ZNews Crawler - Cơ chế xử lý Duplicate ===\")\n",
    "    print(f\"Đã load {len(seen_urls)} URLs và {len(seen_ids)} IDs từ CSV\")\n",
    "    print(f\"END_DATE: {END_DATE}\")\n",
    "    print(f\"Crawling {len(CATEGORY_URLS)} categories...\\n\")\n",
    "\n",
    "    total_added = 0\n",
    "    total_duplicates = 0\n",
    "    total_old = 0\n",
    "    \n",
    "    for cat in CATEGORY_URLS:\n",
    "        try:\n",
    "            added, skipped_duplicate, skipped_old = crawl_category(cat, END_DATE, seen_urls, seen_ids)\n",
    "            total_added += added\n",
    "            total_duplicates += skipped_duplicate\n",
    "            total_old += skipped_old\n",
    "            \n",
    "            # Tính tỷ lệ duplicate\n",
    "            total_found = added + skipped_duplicate + skipped_old\n",
    "            dup_rate = (skipped_duplicate / total_found * 100) if total_found > 0 else 0.0\n",
    "            \n",
    "            print(f\"[{cat}]\")\n",
    "            print(f\"  ✅ Added: {added} bài mới\")\n",
    "            print(f\"  🔄 Duplicates: {skipped_duplicate} bài trùng\")\n",
    "            print(f\"  ⏰ Old: {skipped_old} bài cũ (< {END_DATE})\")\n",
    "            print(f\"  📊 Duplicate rate: {dup_rate:.1f}%\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[{cat}] ❌ ERROR: {e}\\n\")\n",
    "\n",
    "    # Tổng kết\n",
    "    grand_total = total_added + total_duplicates + total_old\n",
    "    overall_dup_rate = (total_duplicates / grand_total * 100) if grand_total > 0 else 0.0\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"📈 TỔNG KẾT:\")\n",
    "    print(f\"  ✅ Tổng bài mới thêm vào CSV: {total_added}\")\n",
    "    print(f\"  🔄 Tổng bài trùng (bỏ qua): {total_duplicates}\")\n",
    "    print(f\"  ⏰ Tổng bài cũ (bỏ qua): {total_old}\")\n",
    "    print(f\"  📊 Tổng bài kiểm tra: {grand_total}\")\n",
    "    print(f\"  💯 Tỷ lệ duplicate: {overall_dup_rate:.1f}%\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\n✅ Hoàn thành! Đã thêm {total_added} bài mới vào {CSV_PATH}\")\n",
    "    \n",
    "    if overall_dup_rate > 70:\n",
    "        print(f\"💡 Gợi ý: Tỷ lệ duplicate cao ({overall_dup_rate:.1f}%) cho thấy crawler đang hoạt động tốt!\")\n",
    "    elif overall_dup_rate < 20 and total_duplicates > 0:\n",
    "        print(f\"⚠️  Lưu ý: Tỷ lệ duplicate thấp ({overall_dup_rate:.1f}%) - có thể có nhiều bài mới hoặc nguồn cập nhật thường xuyên\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f6c4c8",
   "metadata": {},
   "source": [
    "# 24h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2329e770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "24H.COM.VN CRAWLER - Duplicate-Safe Daily Crawling\n",
      "================================================================================\n",
      "\n",
      "📊 Initial state:\n",
      "  - Already crawled: 358 URLs, 358 IDs\n",
      "  - Date filter: Articles >= 2026-01-30\n",
      "  - Total feeds: 11\n",
      "\n",
      "  [trang-chu] RSS entries: 108 | Added: 8 | Duplicates: 100 | Old: 0\n",
      "  [tin-tuc-trong-ngay] RSS entries: 24 | Added: 0 | Duplicates: 24 | Old: 0\n",
      "  [bong-da] RSS entries: 24 | Added: 2 | Duplicates: 22 | Old: 0\n",
      "  [the-thao] RSS entries: 1 | Added: 0 | Duplicates: 0 | Old: 1\n",
      "  [thoi-trang] RSS entries: 24 | Added: 0 | Duplicates: 24 | Old: 0\n",
      "  [hi-tech] RSS entries: 24 | Added: 0 | Duplicates: 24 | Old: 0\n",
      "  [tai-chinh-bat-dong-san] RSS entries: 24 | Added: 0 | Duplicates: 0 | Old: 24\n",
      "  [phim] RSS entries: 24 | Added: 0 | Duplicates: 9 | Old: 15\n",
      "  [giao-duc-du-hoc] RSS entries: 24 | Added: 0 | Duplicates: 24 | Old: 0\n",
      "  [ban-tre-cuoc-song] RSS entries: 24 | Added: 0 | Duplicates: 24 | Old: 0\n",
      "  [the-thao] RSS entries: 24 | Added: 0 | Duplicates: 24 | Old: 0\n",
      "\n",
      "================================================================================\n",
      "✅ CRAWL SUMMARY\n",
      "================================================================================\n",
      "📝 New articles added: 10\n",
      "🔁 Duplicates skipped: 275 (already in CSV)\n",
      "⏰ Old articles skipped: 40 (before 2026-01-30)\n",
      "📊 Total processed: 325\n",
      "💾 Output: 24h_html_categories_vi.csv\n",
      "📈 Total in CSV now: 378 articles\n",
      "================================================================================\n",
      "\n",
      "💡 Duplicate rate: 84.6% - Perfect for daily runs!\n",
      "   (High rate = most articles already crawled = efficient)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import hashlib\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Optional, Dict, Any, List, Set, Tuple\n",
    "\n",
    "import requests\n",
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser as dateparser\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "VN_TZ = timezone(timedelta(hours=7))\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "RSS_FEEDS = [\n",
    "    (\"https://cdn.24h.com.vn/upload/rss/trangchu24h.rss\", \"trang-chu\"),\n",
    "    (\"https://cdn.24h.com.vn/upload/rss/tintuctrongngay.rss\", \"tin-tuc-trong-ngay\"),\n",
    "    (\"https://cdn.24h.com.vn/upload/rss/bongda.rss\", \"bong-da\"),\n",
    "    (\"https://cdn.24h.com.vn/upload/rss/asiancup2019.rss\", \"the-thao\"),\n",
    "    (\"https://cdn.24h.com.vn/upload/rss/thoitrang.rss\", \"thoi-trang\"),\n",
    "    (\"https://cdn.24h.com.vn/upload/rss/thoitranghitech.rss\", \"hi-tech\"),\n",
    "    (\"https://cdn.24h.com.vn/upload/rss/taichinhbatdongsan.rss\", \"tai-chinh-bat-dong-san\"),\n",
    "    (\"https://cdn.24h.com.vn/upload/rss/phim.rss\", \"phim\"),\n",
    "    (\"https://cdn.24h.com.vn/upload/rss/giaoducduhoc.rss\", \"giao-duc-du-hoc\"),\n",
    "    (\"https://cdn.24h.com.vn/upload/rss/bantrecuocsong.rss\", \"ban-tre-cuoc-song\"),\n",
    "    (\"https://cdn.24h.com.vn/upload/rss/thethao.rss\", \"the-thao\"),\n",
    "]\n",
    "\n",
    "# Crawl từ mới -> cũ cho tới khi bài có ngày < END_DATE (theo giờ VN)\n",
    "# Lưu ý: RSS của 24h chỉ cung cấp ~5 ngày data gần nhất\n",
    "END_DATE = \"2026-01-30\"  # YYYY-MM-DD (điều chỉnh phù hợp với RSS limitation)\n",
    "\n",
    "CSV_PATH = \"24h_html_categories_vi.csv\"\n",
    "\n",
    "TIMEOUT = 25\n",
    "REQUEST_DELAY_BASE = 0.25\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; 24hHTMLCrawler/1.0)\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "}\n",
    "# ===========================================\n",
    "\n",
    "CSV_HEADER = [\n",
    "    \"id\",\n",
    "    \"title\",\n",
    "    \"published_at\",\n",
    "    \"source.name\",\n",
    "    \"url\",\n",
    "    \"language\",\n",
    "    \"category.primary\",\n",
    "    \"keywords\",\n",
    "    \"entities\",\n",
    "    \"content.text\",\n",
    "]\n",
    "\n",
    "SOURCE_NAME = \"24h\"\n",
    "DEFAULT_LANGUAGE = \"vi\"\n",
    "DEBUG = False\n",
    "\n",
    "# ----- HTTP session with retry -----\n",
    "session = requests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "retry = Retry(\n",
    "    total=6,\n",
    "    connect=6,\n",
    "    read=6,\n",
    "    backoff_factor=0.6,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"GET\", \"HEAD\"],\n",
    "    respect_retry_after_header=True,\n",
    "    raise_on_status=False,\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry, pool_connections=50, pool_maxsize=50)\n",
    "session.mount(\"http://\", adapter)\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "\n",
    "def log(msg: str):\n",
    "    if DEBUG:\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "def polite_sleep():\n",
    "    time.sleep(REQUEST_DELAY_BASE + random.uniform(0, 0.4))\n",
    "\n",
    "\n",
    "def md5_id(text: str) -> str:\n",
    "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def fetch_text(url: str) -> str:\n",
    "    r = session.get(url, timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    # Xử lý encoding đặc biệt của 24h\n",
    "    r.encoding = r.apparent_encoding or 'utf-8'\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def fetch_rss(rss_url: str) -> feedparser.FeedParserDict:\n",
    "    \"\"\"Fetch và parse RSS feed, xử lý encoding đúng cách\"\"\"\n",
    "    r = session.get(rss_url, timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    # Feedparser tự xử lý encoding\n",
    "    feed = feedparser.parse(r.content)\n",
    "    return feed\n",
    "\n",
    "\n",
    "def to_iso_utc(s: Optional[str]) -> Optional[str]:\n",
    "    if not s:\n",
    "        return None\n",
    "    try:\n",
    "        dt = dateparser.parse(s)\n",
    "        if not dt:\n",
    "            return None\n",
    "        if dt.tzinfo is None:\n",
    "            if VN_TZ:\n",
    "                dt = dt.replace(tzinfo=VN_TZ)\n",
    "            else:\n",
    "                dt = dt.replace(tzinfo=timezone.utc)\n",
    "        return dt.astimezone(timezone.utc).isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def iso_to_local_date(iso_utc: str) -> Optional[str]:\n",
    "    if not iso_utc:\n",
    "        return None\n",
    "    try:\n",
    "        dt = dateparser.parse(iso_utc)\n",
    "        if not dt:\n",
    "            return None\n",
    "        if dt.tzinfo is None:\n",
    "            dt = dt.replace(tzinfo=timezone.utc)\n",
    "        if VN_TZ:\n",
    "            dt_local = dt.astimezone(VN_TZ)\n",
    "        else:\n",
    "            dt_local = dt\n",
    "        return dt_local.date().isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def ensure_csv_header(csv_path: str):\n",
    "    if not os.path.exists(csv_path) or os.path.getsize(csv_path) == 0:\n",
    "        with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow(CSV_HEADER)\n",
    "\n",
    "\n",
    "def load_seen_from_csv(csv_path: str) -> Tuple[Set[str], Set[str]]:\n",
    "    seen_urls, seen_ids = set(), set()\n",
    "    if not os.path.exists(csv_path):\n",
    "        return seen_urls, seen_ids\n",
    "    try:\n",
    "        with open(csv_path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            r = csv.reader(f)\n",
    "            header = next(r, None)\n",
    "            if not header:\n",
    "                return seen_urls, seen_ids\n",
    "            id_idx = header.index(\"id\") if \"id\" in header else 0\n",
    "            url_idx = header.index(\"url\") if \"url\" in header else 4\n",
    "            for row in r:\n",
    "                if len(row) > url_idx:\n",
    "                    u = row[url_idx].strip()\n",
    "                    if u:\n",
    "                        seen_urls.add(u)\n",
    "                if len(row) > id_idx:\n",
    "                    i = row[id_idx].strip()\n",
    "                    if i:\n",
    "                        seen_ids.add(i)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return seen_urls, seen_ids\n",
    "\n",
    "\n",
    "def append_row(csv_path: str, row: Dict[str, Any]):\n",
    "    with open(csv_path, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([row.get(k, \"\") for k in CSV_HEADER])\n",
    "        f.flush()\n",
    "\n",
    "\n",
    "def extract_language_from_html(soup: BeautifulSoup) -> str:\n",
    "    html_tag = soup.find(\"html\")\n",
    "    if html_tag:\n",
    "        lang = html_tag.get(\"lang\") or html_tag.get(\"xml:lang\")\n",
    "        if lang:\n",
    "            lang = lang.lower().strip()\n",
    "            if lang.startswith(\"vi\"):\n",
    "                return \"vi\"\n",
    "            if lang.startswith(\"en\"):\n",
    "                return \"en\"\n",
    "            return lang\n",
    "    return DEFAULT_LANGUAGE\n",
    "\n",
    "\n",
    "def extract_keywords_from_html(soup: BeautifulSoup) -> List[str]:\n",
    "    for sel in ['meta[name=\"keywords\"]', 'meta[name=\"news_keywords\"]']:\n",
    "        tag = soup.select_one(sel)\n",
    "        if tag and tag.get(\"content\"):\n",
    "            raw = tag[\"content\"]\n",
    "            kws = [x.strip() for x in raw.split(\",\") if x.strip()]\n",
    "            seen = set()\n",
    "            out = []\n",
    "            for k in kws:\n",
    "                if k not in seen:\n",
    "                    seen.add(k)\n",
    "                    out.append(k)\n",
    "            return out\n",
    "    return []\n",
    "\n",
    "\n",
    "def extract_article_meta(article_html: str) -> Dict[str, Any]:\n",
    "    soup = BeautifulSoup(article_html, \"lxml\")\n",
    "\n",
    "    # title\n",
    "    title = \"\"\n",
    "    og = soup.select_one('meta[property=\"og:title\"]')\n",
    "    if og and og.get(\"content\"):\n",
    "        title = og[\"content\"].strip()\n",
    "    if not title:\n",
    "        h1 = soup.select_one(\"h1.title-detail, h1.cate-24h-title-detail, h1\")\n",
    "        if h1:\n",
    "            title = h1.get_text(strip=True)\n",
    "\n",
    "    # published_at\n",
    "    pub = \"\"\n",
    "    m_pub = soup.select_one('meta[property=\"article:published_time\"]')\n",
    "    if m_pub and m_pub.get(\"content\"):\n",
    "        pub = to_iso_utc(m_pub[\"content\"].strip()) or \"\"\n",
    "    if not pub:\n",
    "        m2 = soup.select_one('meta[itemprop=\"datePublished\"]')\n",
    "        if m2 and m2.get(\"content\"):\n",
    "            pub = to_iso_utc(m2[\"content\"].strip()) or \"\"\n",
    "    if not pub:\n",
    "        ttag = soup.select_one(\"time\")\n",
    "        if ttag:\n",
    "            pub = to_iso_utc(ttag.get(\"datetime\") or ttag.get_text(strip=True)) or \"\"\n",
    "    if not pub:\n",
    "        # 24h có thể dùng class .cate-24h-date-published\n",
    "        date_pub = soup.select_one(\".cate-24h-date-published\")\n",
    "        if date_pub:\n",
    "            pub = to_iso_utc(date_pub.get_text(strip=True)) or \"\"\n",
    "\n",
    "    # category.primary\n",
    "    category_primary = \"\"\n",
    "    sec = soup.select_one('meta[property=\"article:section\"]')\n",
    "    if sec and sec.get(\"content\"):\n",
    "        category_primary = sec[\"content\"].strip()\n",
    "\n",
    "    language = extract_language_from_html(soup)\n",
    "    keywords = extract_keywords_from_html(soup)\n",
    "\n",
    "    # content.text - 24h thường dùng class .cate-24h-content-text\n",
    "    content_text = \"\"\n",
    "    article_body = soup.select_one(\".cate-24h-content-text\")\n",
    "    if not article_body:\n",
    "        article_body = soup.select_one(\"article .content-text\")\n",
    "    if not article_body:\n",
    "        article_body = soup.select_one(\".content-text\")\n",
    "    if not article_body:\n",
    "        article_body = soup.select_one(\".article-content\")\n",
    "    if not article_body:\n",
    "        article_body = soup.select_one(\"article\")\n",
    "    \n",
    "    if article_body:\n",
    "        paragraphs = article_body.find_all(\"p\")\n",
    "        text_parts = []\n",
    "        for p in paragraphs:\n",
    "            text = p.get_text(strip=True)\n",
    "            if text:\n",
    "                text_parts.append(text)\n",
    "        content_text = \" \".join(text_parts)\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"published_at\": pub,\n",
    "        \"language\": language,\n",
    "        \"keywords\": keywords,\n",
    "        \"category_from_article\": category_primary,\n",
    "        \"entities\": [],\n",
    "        \"content_text\": content_text,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_row(url: str, meta: Dict[str, Any], category_fallback: str) -> Dict[str, Any]:\n",
    "    id_ = md5_id(url)\n",
    "    category_primary = meta.get(\"category_from_article\") or category_fallback\n",
    "    keywords_str = \"|\".join(meta.get(\"keywords\") or [])\n",
    "    entities_str = \"|\".join(meta.get(\"entities\") or [])\n",
    "\n",
    "    return {\n",
    "        \"id\": id_,\n",
    "        \"title\": meta.get(\"title\") or \"\",\n",
    "        \"published_at\": meta.get(\"published_at\") or \"\",\n",
    "        \"source.name\": SOURCE_NAME,\n",
    "        \"url\": url,\n",
    "        \"language\": meta.get(\"language\") or DEFAULT_LANGUAGE,\n",
    "        \"category.primary\": category_primary or \"\",\n",
    "        \"keywords\": keywords_str,\n",
    "        \"entities\": entities_str,\n",
    "        \"content.text\": meta.get(\"content_text\") or \"\",\n",
    "    }\n",
    "\n",
    "\n",
    "def crawl_rss_feed(rss_url: str, category_slug: str, end_date: str, \n",
    "                   seen_urls: Set[str], seen_ids: Set[str]) -> Tuple[int, int, int]:\n",
    "    \"\"\"\n",
    "    Crawl articles từ RSS feed\n",
    "    Returns: (added, skipped_duplicate, skipped_old)\n",
    "    \"\"\"\n",
    "    added = 0\n",
    "    skipped_old = 0\n",
    "    skipped_duplicate = 0\n",
    "    \n",
    "    try:\n",
    "        feed = fetch_rss(rss_url)\n",
    "    except Exception as e:\n",
    "        log(f\"[WARN] RSS fetch failed {rss_url}: {e}\")\n",
    "        return (0, 0, 0)\n",
    "    \n",
    "    if not feed.entries:\n",
    "        log(f\"[WARN] No entries in RSS feed {rss_url}\")\n",
    "        return (0, 0, 0)\n",
    "    \n",
    "    for entry in feed.entries:\n",
    "        article_url = entry.get(\"link\", \"\").strip()\n",
    "        if not article_url:\n",
    "            continue\n",
    "            \n",
    "        # Normalize URL\n",
    "        if not article_url.startswith(\"http\"):\n",
    "            article_url = \"https://www.24h.com.vn\" + article_url\n",
    "        \n",
    "        # Lấy published date từ RSS để check trước\n",
    "        pub_date_rss = entry.get(\"published\") or entry.get(\"updated\")\n",
    "        pub_iso_rss = to_iso_utc(pub_date_rss) if pub_date_rss else \"\"\n",
    "        pub_local_date = iso_to_local_date(pub_iso_rss) or \"\"\n",
    "        \n",
    "        # Skip articles older than END_DATE trước khi check duplicate\n",
    "        # Vì RSS được sắp xếp theo thời gian, có thể early exit\n",
    "        if pub_local_date and pub_local_date < end_date:\n",
    "            skipped_old += 1\n",
    "            continue\n",
    "            \n",
    "        # Check duplicate - QUAN TRỌNG: Skip nếu đã crawl\n",
    "        # Khi chạy hàng ngày, đa số articles sẽ bị skip ở đây\n",
    "        if article_url in seen_urls:\n",
    "            skipped_duplicate += 1\n",
    "            continue\n",
    "            \n",
    "        aid = md5_id(article_url)\n",
    "        if aid in seen_ids:\n",
    "            skipped_duplicate += 1\n",
    "            continue\n",
    "        \n",
    "        # Fetch full article content (chỉ với articles mới)\n",
    "        try:\n",
    "            article_html = fetch_text(article_url)\n",
    "            meta = extract_article_meta(article_html)\n",
    "        except Exception as e:\n",
    "            log(f\"[WARN] article fetch failed {article_url}: {e}\")\n",
    "            # Fallback: use RSS data\n",
    "            meta = {\n",
    "                \"title\": entry.get(\"title\", \"\"),\n",
    "                \"published_at\": pub_iso_rss,\n",
    "                \"language\": DEFAULT_LANGUAGE,\n",
    "                \"keywords\": [],\n",
    "                \"category_from_article\": \"\",\n",
    "                \"entities\": [],\n",
    "                \"content_text\": BeautifulSoup(entry.get(\"summary\", \"\"), \"lxml\").get_text(strip=True),\n",
    "            }\n",
    "        finally:\n",
    "            polite_sleep()\n",
    "        \n",
    "        # Use RSS published date if article doesn't have one\n",
    "        if not meta.get(\"published_at\") and pub_iso_rss:\n",
    "            meta[\"published_at\"] = pub_iso_rss\n",
    "        \n",
    "        row = make_row(article_url, meta, category_fallback=category_slug)\n",
    "        append_row(CSV_PATH, row)\n",
    "        seen_urls.add(article_url)\n",
    "        seen_ids.add(aid)\n",
    "        added += 1\n",
    "    \n",
    "    # Always show summary for transparency\n",
    "    print(f\"  [{category_slug}] RSS entries: {len(feed.entries)} | Added: {added} | Duplicates: {skipped_duplicate} | Old: {skipped_old}\")\n",
    "    \n",
    "    return (added, skipped_duplicate, skipped_old)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*80)\n",
    "    print(f\"24H.COM.VN CRAWLER - Duplicate-Safe Daily Crawling\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    ensure_csv_header(CSV_PATH)\n",
    "    seen_urls, seen_ids = load_seen_from_csv(CSV_PATH)\n",
    "    \n",
    "    print(f\"\\n📊 Initial state:\")\n",
    "    print(f\"  - Already crawled: {len(seen_urls)} URLs, {len(seen_ids)} IDs\")\n",
    "    print(f\"  - Date filter: Articles >= {END_DATE}\")\n",
    "    print(f\"  - Total feeds: {len(RSS_FEEDS)}\")\n",
    "    print()\n",
    "\n",
    "    total_added = 0\n",
    "    total_duplicates = 0\n",
    "    total_old = 0\n",
    "    \n",
    "    for rss_url, category_slug in RSS_FEEDS:\n",
    "        try:\n",
    "            added, duplicates, old = crawl_rss_feed(rss_url, category_slug, END_DATE, seen_urls, seen_ids)\n",
    "            total_added += added\n",
    "            total_duplicates += duplicates\n",
    "            total_old += old\n",
    "        except Exception as e:\n",
    "            print(f\"  [{category_slug}] ERROR: {e}\")\n",
    "\n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    print(f\"✅ CRAWL SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"📝 New articles added: {total_added}\")\n",
    "    print(f\"🔁 Duplicates skipped: {total_duplicates} (already in CSV)\")\n",
    "    print(f\"⏰ Old articles skipped: {total_old} (before {END_DATE})\")\n",
    "    print(f\"📊 Total processed: {total_added + total_duplicates + total_old}\")\n",
    "    print(f\"💾 Output: {CSV_PATH}\")\n",
    "    print(f\"📈 Total in CSV now: {len(seen_urls) + total_added} articles\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if total_duplicates > 0:\n",
    "        efficiency = (total_duplicates / (total_added + total_duplicates + total_old) * 100) if (total_added + total_duplicates + total_old) > 0 else 0\n",
    "        print(f\"\\n💡 Duplicate rate: {efficiency:.1f}% - Perfect for daily runs!\")\n",
    "        print(f\"   (High rate = most articles already crawled = efficient)\")\n",
    "    print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
